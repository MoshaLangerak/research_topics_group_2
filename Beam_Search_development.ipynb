{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:28:57.019960Z",
     "start_time": "2024-10-10T12:28:48.758360Z"
    }
   },
   "source": [
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "from load_data_old import make_growth_target_df\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from itertools import combinations"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## aantekeningen\n",
    "\\\n",
    "windowsize is erg bepalend in welke subgroups de hoogste quality measure halen (max 72 vs 250 bij 7 vs 5 windowsize) \\\n",
    "\\\n",
    "windowsize, windowoverlap en aggregate functies moeten nog als input aan beam search toegevoegd worden (voor de quality measure) \\\n",
    "\\\n",
    "we doen nu alleen equal voor classes column maar moet ook niet not equal? (dan neemt mogelijke optie wel gigantish toe (exponentieel??)) \\\n",
    "\\\n",
    "worden de splitpoints voor numerical class nu wel goed berekent en hoeveel bins is optimaal? \\\n",
    "\\\n",
    "is equalsized bins de beste optie? \\\n",
    "\\\n",
    "in de results opslaan hoe groot de subgroup is \\ \n",
    "\\ \n",
    "als je max gebruikt over de z_scores gaat hij dan niet altijd opzoek naar een subgroup waar een gigantische outlier een onderdeel van is?\\\n",
    "\\\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:28:57.051874Z",
     "start_time": "2024-10-10T12:28:57.038092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Timing decorator to profile any function\n",
    "def time_function(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Function {func.__name__} took {end_time - start_time:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:27:24.361093Z",
     "start_time": "2024-10-10T15:27:24.255723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gt(a, b):\n",
    "    \"\"\"Returns True if a is greater than b.\"\"\"\n",
    "    return a > b\n",
    "\n",
    "def leeq(a, b):\n",
    "    \"\"\"Returns True if a is less than or equal to b.\"\"\"\n",
    "    return a <= b\n",
    "\n",
    "def eq(a, b):\n",
    "    \"\"\"Returns True if a is equal to b.\"\"\"\n",
    "    return a == b\n",
    "\n",
    "def neq(a, b):\n",
    "    \"\"\"Returns True if a is not equal to b.\"\"\"\n",
    "    return not eq(a, b)\n",
    "\n",
    "def extract_subgroup(descriptors, data, col_index_dict):\n",
    "    \"\"\"Extracts a subgroup of data that matches all provided descriptors.\n",
    "\n",
    "    Args:\n",
    "        descriptors: A list of descriptors, each containing an attribute name, value, and operator.\n",
    "        data: The dataset from which to extract the subgroup.\n",
    "        col_index_dict: A dictionary mapping column names to their indices.\n",
    "\n",
    "    Returns:\n",
    "        A list of rows from the data that match all descriptors.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for row in data:\n",
    "        check = True\n",
    "        for attribute in descriptors:\n",
    "            att_name, descr_value, operator = attribute  # unpack 3 values from attribute\n",
    "            att_index = col_index_dict[att_name]  # get the index for the attribute\n",
    "            value = operator(row[att_index], descr_value)  # apply the operator\n",
    "\n",
    "            if not value:  # if any descriptor does not match\n",
    "                check = False\n",
    "                break\n",
    "\n",
    "        if check:  # if all descriptors match\n",
    "            result.append(row)  # add the row to the result\n",
    "\n",
    "    return result\n",
    "\n",
    "def refin(seed, data, types, nr_bins, descr_indices, index_col_dict, col_index_dict):\n",
    "    \"\"\"Generates new descriptor sets by refining the seed descriptors.\n",
    "\n",
    "    Args:\n",
    "        seed: The initial set of descriptors to refine.\n",
    "        data: The dataset used for extracting subgroups.\n",
    "        types: The types of each column in the dataset.\n",
    "        nr_bins: The number of bins to create for numeric attributes.\n",
    "        descr_indices: The indices of potential descriptors.\n",
    "        index_col_dict: A dictionary mapping index to column names.\n",
    "        col_index_dict: A dictionary mapping column names to indices.\n",
    "\n",
    "    Returns:\n",
    "        A list of new descriptor sets created by refining the seed.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    used_descr = [col_index_dict[i[0]] for i in seed]  # get used descriptors\n",
    "    not_used_indices = descr_indices[:]  # make a copy of descriptor indices\n",
    "    # Filter out indices that are already used or are numeric types\n",
    "    not_used_indices = [i for i in not_used_indices if i not in used_descr or types[i] == \"numeric\"]\n",
    "\n",
    "    for i in not_used_indices:\n",
    "        aux = list(seed)[:]  # copy the seed\n",
    "\n",
    "        if types[i] == 'numeric':\n",
    "            s = extract_subgroup(seed, data, col_index_dict)  # extract subgroup based on seed\n",
    "            all_values = [float(entry[i]) for entry in s]  # get all values for the numeric attribute\n",
    "            all_values = sorted(all_values)  # sort values\n",
    "            n = len(all_values)\n",
    "            # Create split points for binning\n",
    "            split_points = [all_values[math.floor(j * (n/nr_bins))] for j in range(1, nr_bins)]\n",
    "            for s in split_points:\n",
    "                func1 = leeq\n",
    "                func2 = gt\n",
    "\n",
    "                # Create two new descriptors for each split point\n",
    "                local0 = aux[:]\n",
    "                local0.append((index_col_dict[i], s, func1))  # descriptor for less than or equal\n",
    "                res.append(local0)\n",
    "\n",
    "                local1 = aux[:]\n",
    "                local1.append((index_col_dict[i], s, func2))  # descriptor for greater than\n",
    "                res.append(local1)\n",
    "\n",
    "        elif types[i] == 'binary':\n",
    "            func = eq  # equality function for binary descriptors\n",
    "            local0 = aux[:]\n",
    "            local0.append((index_col_dict[i], 0, func))  # descriptor for value 0\n",
    "            local1 = aux[:]\n",
    "            local1.append((index_col_dict[i], 1, func))  # descriptor for value 1\n",
    "            res.append(local0)\n",
    "            res.append(local1)\n",
    "\n",
    "        else:  # nominal attributes\n",
    "            all_values = [entry[i] for entry in data]  # get all unique values\n",
    "            for j in set(all_values):\n",
    "                func1 = eq\n",
    "                func2 = neq\n",
    "                local0 = aux[:]\n",
    "                local0.append((index_col_dict[i], j, func1))  # descriptor for equality\n",
    "                res.append(local0)\n",
    "                # local1 = aux[:]\n",
    "                # local1.append((index_col_dict[i], j, func2))  # descriptor for not equality\n",
    "                # res.append(local1)\n",
    "\n",
    "    return res\n",
    "\n",
    "def put_item_in_queue(queue, quality, descriptor, size=0, t=0):\n",
    "    \"\"\"Adds an item to a priority queue based on its quality.\n",
    "\n",
    "    Args:\n",
    "        queue: The priority queue to which the item will be added.\n",
    "        quality: The quality measure of the item.\n",
    "        descriptor: The descriptor associated with the item.\n",
    "        size: The size of the subgroup represented by the descriptor.\n",
    "    \"\"\"\n",
    "    if queue.full():  # if the queue is full\n",
    "        min_quality, min_descriptor, min_size, min_t = queue.get()  # get the lowest quality item\n",
    "        if min_quality >= quality:  # if the new item is not better, put the old one back\n",
    "            queue.put((min_quality, min_descriptor, min_size, min_t))\n",
    "        else:  # otherwise, add the new item\n",
    "            queue.put((quality, descriptor, size, t))\n",
    "    else:\n",
    "        queue.put((quality, descriptor, size, t))  # add new item to the queue\n",
    "\n",
    "def categorize_columns_in_order(df, att_columns):\n",
    "    \"\"\"Categorizes columns of a DataFrame into numeric, binary, and nominal types.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame containing the data.\n",
    "        att_columns: The columns to categorize.\n",
    "\n",
    "    Returns:\n",
    "        A list of column types corresponding to the provided attribute columns.\n",
    "    \"\"\"\n",
    "    column_types = []  # List to store the categories in order\n",
    "\n",
    "    for col in att_columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):  # Check if the column is numeric\n",
    "            column_types.append('numeric')\n",
    "        elif df[col].nunique() == 2:  # Check for binary columns\n",
    "            column_types.append('binary')\n",
    "        else:  # Otherwise, treat it as nominal\n",
    "            column_types.append('nominal')\n",
    "\n",
    "    return column_types\n",
    "\n",
    "def make_rolling_windows(growth_target, window_size):\n",
    "    \"\"\"Creates rolling windows for the target data.\n",
    "\n",
    "    Args:\n",
    "        growth_target: The target data for which to create rolling windows.\n",
    "        window_size: The size of each window.\n",
    "\n",
    "    Returns:\n",
    "        A new array of rolling windows.\n",
    "    \"\"\"\n",
    "    return np.lib.stride_tricks.sliding_window_view(growth_target, window_shape=window_size)[::window_size]\n",
    "\n",
    "def quality_measure(targets_subgroup, targets_baseline,\n",
    "                    aggregate_func_window=np.mean, aggregate_func=np.max):\n",
    "    \"\"\"Calculates a quality measure for a subgroup compared to a baseline.\n",
    "\n",
    "    Args:\n",
    "        targets_subgroup: list with timeseries where the timeseries are divided in windows (list with lists with lists)\n",
    "        targets_baseline: list with baseline target values in windows (list with lists).\n",
    "        aggregate_func_window: Function to aggregate over windows (default: mean).\n",
    "        aggregate_func: Function to aggregate the final quality measure (default: max).\n",
    "\n",
    "    Returns:\n",
    "        A quality score representing the difference between the subgroup and baseline.\n",
    "    \"\"\"\n",
    "    # Aggregate points in each window for each timeseries in the subgroup\n",
    "    subgroup_aggregated_windows = aggregate_func_window(targets_subgroup, axis=2)\n",
    "\n",
    "    # Calculate mean values for the baseline and subgroup for each window\n",
    "    baseline_means = np.mean(targets_baseline, axis=1)\n",
    "    subgroup_means = np.mean(subgroup_aggregated_windows, axis=0)\n",
    "\n",
    "    # Calculate absolute differences between means for each window\n",
    "    abs_diff_mean = np.abs(subgroup_means - baseline_means)\n",
    "\n",
    "    # Calculate standard error of the subgroup for each window\n",
    "    subgroup_std = np.std(subgroup_aggregated_windows, axis=0)\n",
    "    standard_error_subgroup = subgroup_std #/ np.sqrt(len(targets_subgroup))\n",
    "\n",
    "    # Calculate z-scores\n",
    "    z_scores = np.divide(abs_diff_mean, standard_error_subgroup, where=standard_error_subgroup != 0)\n",
    "\n",
    "    # Calculate the final quality score\n",
    "    quality_score = aggregate_func(z_scores)\n",
    "\n",
    "    return quality_score\n",
    "\n",
    "\n",
    "def beam_search(data, targets_baseline, column_names, beam_width, beam_depth, nr_bins, nr_saved, subgroup_size, target, types, window_size, max_subgroup_size=100000):\n",
    "    \"\"\"Performs beam search to identify optimal descriptors for subgroups.\n",
    "\n",
    "    Args:\n",
    "        data: The dataset to analyze.\n",
    "        targets_baseline: The baseline target values for comparison.\n",
    "        column_names: The names of the columns in the dataset.\n",
    "        beam_width: The number of descriptors to keep at each depth level.\n",
    "        beam_depth: The maximum depth of the beam search.\n",
    "        nr_bins: The number of bins to create for numeric attributes.\n",
    "        nr_saved: The number of best results to save.\n",
    "        subgroup_size: The minimum size of a subgroup to consider.\n",
    "        target: The target variable for which to evaluate subgroups.\n",
    "        types: The types of each column in the dataset (e.g., numeric, binary, nominal).\n",
    "        window_size: The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        A list of the best descriptor sets found during the search.\n",
    "    \"\"\"\n",
    "    # Create dictionaries for indexing columns by name and vice versa\n",
    "    index_col_dict = {i: col for i, col in enumerate(column_names)}\n",
    "    col_index_dict = {col: i for i, col in enumerate(column_names)}\n",
    "    target_ind = column_names.index(target)  # Get index of the target column\n",
    "    att_indices = list(range(len(column_names)))  # Create a list of all indices\n",
    "    att_indices.remove(target_ind)  # Remove the target index from attribute indices\n",
    "\n",
    "    # Prepare data windows with rolling windows for the target variable\n",
    "    data_windows = []\n",
    "    for row in data:\n",
    "        new_row = row[:]  # Create a copy of the row\n",
    "        new_row[target_ind] = make_rolling_windows(row[target_ind], window_size)  # Apply rolling window\n",
    "        data_windows.append(new_row)  # Add the new row to data_windows\n",
    "\n",
    "    # Update the data and baseline targets to use rolling windows\n",
    "    data = data_windows\n",
    "    targets_baseline = make_rolling_windows(targets_baseline, window_size)\n",
    "\n",
    "    # Initialize a deque for the beam search and a priority queue for results\n",
    "    beam_queue = deque([()])  # Start with an empty seed\n",
    "    results = PriorityQueue(nr_saved)  # Queue to hold the best results\n",
    "\n",
    "    # Iterate through each depth of the beam search\n",
    "    for depth in range(beam_depth):\n",
    "        beam = PriorityQueue(beam_width)  # Initialize a new beam for this depth\n",
    "\n",
    "        # While there are seeds in the beam queue\n",
    "        while bool(beam_queue):\n",
    "            seed = beam_queue.popleft()  # Get the next seed descriptor\n",
    "            descriptor_set = refin(seed, data, types, nr_bins, att_indices, index_col_dict, col_index_dict)  # Refine descriptors based on seed\n",
    "\n",
    "            # Evaluate each descriptor set generated\n",
    "            for descriptor in descriptor_set:\n",
    "                subgroup = extract_subgroup(descriptor, data, col_index_dict)  # Extract subgroup for the current descriptor\n",
    "                if len(subgroup) >= subgroup_size and len(subgroup)<max_subgroup_size:  # Ensure subgroup is large enough\n",
    "                    targets_subgroup = [i[target_ind] for i in subgroup]  # Extract target values for the subgroup\n",
    "                    quality_result = quality_measure(targets_subgroup, targets_baseline)  # Calculate quality measure\n",
    "                    put_item_in_queue(results, quality_result, tuple(descriptor), len(subgroup))  # Add to results queue\n",
    "                    put_item_in_queue(beam, quality_result, tuple(descriptor))  # Add to the current beam\n",
    "\n",
    "        # After processing the beam, update the beam queue with new combinations\n",
    "        while not beam.empty():\n",
    "            new_combination = beam.get()  # Get the highest quality descriptor from the beam\n",
    "            new_combination = new_combination[1]  # Extract the descriptor from the tuple\n",
    "            beam_queue.append(new_combination)  # Add it to the next depth of the beam search\n",
    "\n",
    "    # Compile results into a list and reverse to have the best results first\n",
    "    results_list = []\n",
    "    while not results.empty():\n",
    "        item = results.get()  # Get items from the results queue\n",
    "        results_list.append(item)  # Add to the results list\n",
    "    results_list.reverse()  # Reverse the list to have best results first\n",
    "\n",
    "    return results_list  # Return the list of best descriptor sets\n",
    "\n",
    "\n",
    "def filter_df_on_descriptors(df, descriptors):\n",
    "    \"\"\"Filters a DataFrame based on specified descriptors.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame to filter.\n",
    "        descriptors: A list of descriptors, each containing an attribute name, value, and operator.\n",
    "\n",
    "    Returns:\n",
    "        A filtered DataFrame where all descriptors hold true.\n",
    "    \"\"\"\n",
    "    # Loop through each descriptor to apply filtering\n",
    "    for desc in descriptors:\n",
    "        # Apply the operator defined in the descriptor to filter the DataFrame\n",
    "        df = df[df[desc[0]].apply(lambda x: desc[2](x, desc[1]))]  # Filter based on the descriptor\n",
    "    return df  # Return the filtered DataFrame\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "################# BEAM SEARCH WITH (SELF MADE) CONSTRAINT #################################################\n",
    "### it is finished but not perfect and complicated, maybe finding something in the literature is better ###\n",
    "###########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "def get_all_descriptors(pq, index):\n",
    "    \"\"\"Retrieve all descriptors from a priority queue without altering its contents.\n",
    "\n",
    "    Args:\n",
    "        pq: A priority queue containing descriptor tuples.\n",
    "\n",
    "    Returns:\n",
    "        A list of descriptors.\n",
    "    \"\"\"\n",
    "    temp_items = []  # Temporary list to store all items from the queue\n",
    "    info = []  # List to store descriptors\n",
    "\n",
    "    # Step 1: Retrieve all items from the queue\n",
    "    while not pq.empty():\n",
    "        item = pq.get()  # Get item from the queue\n",
    "        temp_items.append(item)  # Store the item temporarily\n",
    "        info.append(item[index])  # Extract and store the descriptor\n",
    "\n",
    "    # Step 2: Put all items back into the queue to maintain its original state\n",
    "    for item in temp_items:\n",
    "        pq.put(item)\n",
    "\n",
    "    # Step 3: Return the list of all descriptors\n",
    "    return info\n",
    "\n",
    "\n",
    "def are_descriptors_similar(descriptor1, pq):\n",
    "    \"\"\"Check if the given descriptor is similar to any descriptors in the priority queue.\n",
    "\n",
    "    Args:\n",
    "        descriptor1: The first descriptor to compare (a list of (metric, value, func) tuples).\n",
    "        pq: A priority queue containing other descriptors.\n",
    "\n",
    "    Returns:\n",
    "        True if a similar descriptor is found in the queue, False otherwise.\n",
    "    \"\"\"\n",
    "    tolerance = 0.25  # Tolerance range for numeric comparison\n",
    "    desc1_dict = {metric: (value, func) for metric, value, func in descriptor1}  # Convert descriptor1 to a dictionary\n",
    "    descriptor_list = get_all_descriptors(pq, 1)  # Get all descriptors from the queue\n",
    "\n",
    "    # Iterate through each descriptor in the list\n",
    "    for descriptor2 in descriptor_list:\n",
    "        desc2_dict = {metric: (value, func) for metric, value, func in descriptor2}  # Convert descriptor2 to a dictionary\n",
    "\n",
    "        # If the length of descriptors doesn't match, skip\n",
    "        if len(desc1_dict) != len(desc2_dict):\n",
    "            continue\n",
    "\n",
    "        all_metrics_match = True  # Flag to track if all metrics match\n",
    "\n",
    "        # Check each metric in descriptor1\n",
    "        for metric in desc1_dict:\n",
    "            if metric in desc2_dict:\n",
    "                value1, func1 = desc1_dict[metric]\n",
    "                value2, func2 = desc2_dict[metric]\n",
    "\n",
    "                # Check if the functions are the same\n",
    "                if func1 != func2:\n",
    "                    all_metrics_match = False\n",
    "                    break\n",
    "\n",
    "                # Check if numeric values are within tolerance range\n",
    "                if (not isinstance(value1, str)) and abs(value1 - value2) > abs(tolerance * value1):\n",
    "                    all_metrics_match = False\n",
    "                    break\n",
    "\n",
    "                # For strings, check if values are exactly the same\n",
    "                if isinstance(value1, str) and value1 != value2:\n",
    "                    all_metrics_match = False\n",
    "                    break\n",
    "            else:\n",
    "                # If metric in descriptor1 is not in descriptor2, they are not similar\n",
    "                all_metrics_match = False\n",
    "                break\n",
    "\n",
    "        # If all metrics match, return True (descriptors are similar)\n",
    "        if all_metrics_match:\n",
    "            return True\n",
    "\n",
    "    # If no similar descriptors are found, return False\n",
    "    return False\n",
    "\n",
    "def beam_search_with_constraint_descriptor(data, targets_baseline, column_names, beam_width, beam_depth, nr_bins, nr_saved, subgroup_size, target, types, window_size, max_subgroup_size=100000):\n",
    "    \"\"\"Performs beam search with a constraint to avoid adding similar descriptors.\n",
    "\n",
    "    Args:\n",
    "        data: The dataset to analyze.\n",
    "        targets_baseline: The baseline target values for comparison.\n",
    "        column_names: The names of the columns in the dataset.\n",
    "        beam_width: The number of descriptors to keep at each depth level.\n",
    "        beam_depth: The maximum depth of the beam search.\n",
    "        nr_bins: The number of bins to create for numeric attributes.\n",
    "        nr_saved: The number of best results to save.\n",
    "        subgroup_size: The minimum size of a subgroup to consider.\n",
    "        target: The target variable for which to evaluate subgroups.\n",
    "        types: The types of each column in the dataset (e.g., numeric, binary, nominal).\n",
    "        window_size: The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        A list of the best descriptor sets found during the search, ensuring no similar descriptors.\n",
    "    \"\"\"\n",
    "    # Create dictionaries for indexing columns by name and vice versa\n",
    "    index_col_dict = {i: col for i, col in enumerate(column_names)}\n",
    "    col_index_dict = {col: i for i, col in enumerate(column_names)}\n",
    "    target_ind = column_names.index(target)  # Get index of the target column\n",
    "    att_indices = list(range(len(column_names)))  # Create a list of all indices\n",
    "    att_indices.remove(target_ind)  # Remove the target index from attribute indices\n",
    "\n",
    "    # Prepare data windows with rolling windows for the target variable\n",
    "    data_windows = []\n",
    "    for row in data:\n",
    "        new_row = row[:]  # Create a copy of the row\n",
    "        new_row[target_ind] = make_rolling_windows(row[target_ind], window_size)  # Apply rolling window\n",
    "        data_windows.append(new_row)  # Add the new row to data_windows\n",
    "\n",
    "    # Update the data and baseline targets to use rolling windows\n",
    "    data = data_windows\n",
    "    targets_baseline = make_rolling_windows(targets_baseline, window_size)\n",
    "\n",
    "    # Initialize a deque for the beam search and a priority queue for results\n",
    "    beam_queue = deque([()])  # Start with an empty seed\n",
    "    results = PriorityQueue(nr_saved)  # Queue to hold the best results\n",
    "    results.put((0, [(0, 0, 0)], 0))  # Add a dummy descriptor to initialize\n",
    "\n",
    "    # Iterate through each depth of the beam search\n",
    "    for depth in range(beam_depth):\n",
    "        beam = PriorityQueue(beam_width)  # Initialize a new beam for this depth\n",
    "\n",
    "        # While there are seeds in the beam queue\n",
    "        while bool(beam_queue):\n",
    "            seed = beam_queue.popleft()  # Get the next seed descriptor\n",
    "            descriptor_set = refin(seed, data, types, nr_bins, att_indices, index_col_dict, col_index_dict)  # Refine descriptors based on seed\n",
    "\n",
    "            # Evaluate each descriptor set generated\n",
    "            for descriptor in descriptor_set:\n",
    "                subgroup = extract_subgroup(descriptor, data, col_index_dict)  # Extract subgroup for the current descriptor\n",
    "                if len(subgroup) >= subgroup_size and len(subgroup) < max_subgroup_size and not are_descriptors_similar(descriptor, results):  # Ensure subgroup is large enough and descriptor is not similar\n",
    "                    targets_subgroup = [i[target_ind] for i in subgroup]  # Extract target values for the subgroup\n",
    "                    quality_result = quality_measure(targets_subgroup, targets_baseline)  # Calculate quality measure\n",
    "                    put_item_in_queue(results, quality_result, tuple(descriptor), len(subgroup))  # Add to results queue\n",
    "                    put_item_in_queue(beam, quality_result, tuple(descriptor))  # Add to the current beam\n",
    "\n",
    "        # After processing the beam, update the beam queue with new combinations\n",
    "        while not beam.empty():\n",
    "            new_combination = beam.get()  # Get the highest quality descriptor from the beam\n",
    "            new_combination = new_combination[1]  # Extract the descriptor from the tuple\n",
    "            beam_queue.append(new_combination)  # Add it to the next depth of the beam search\n",
    "\n",
    "    # Compile results into a list and reverse to have the best results first\n",
    "    results_list = []\n",
    "    while not results.empty():\n",
    "        item = results.get()  # Get items from the results queue\n",
    "        results_list.append(item)  # Add to the results list\n",
    "    results_list.reverse()  # Reverse the list to have best results first\n",
    "\n",
    "    return results_list  # Return the list of best descriptor sets\n",
    "\n",
    "def extract_subgroup_index(descriptors, data, col_index_dict):\n",
    "    \"\"\"Extracts a subgroup of data that matches all provided descriptors.\n",
    "\n",
    "    Args:\n",
    "        descriptors: A list of descriptors, each containing an attribute name, value, and operator.\n",
    "        data: The dataset from which to extract the subgroup.\n",
    "        col_index_dict: A dictionary mapping column names to their indices.\n",
    "\n",
    "    Returns:\n",
    "        A list of rows from the data that match all descriptors.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    index_list = []\n",
    "    for i, row in enumerate(data):\n",
    "        check = True\n",
    "        for attribute in descriptors:\n",
    "            att_name, descr_value, operator = attribute  # unpack 3 values from attribute\n",
    "            att_index = col_index_dict[att_name]  # get the index for the attribute\n",
    "            value = operator(row[att_index], descr_value)  # apply the operator\n",
    "    \n",
    "            if not value:  # if any descriptor does not match\n",
    "                check = False\n",
    "                break\n",
    "    \n",
    "        if check:  # if all descriptors match\n",
    "            result.append(row)  # add the row to the result\n",
    "            index_list.append(i)\n",
    "    \n",
    "    return result, index_list\n",
    "\n",
    "def beam_search_with_constraint_cover(data, targets_baseline, column_names, beam_width, beam_depth, nr_bins, nr_saved, subgroup_size, target, types, window_size, max_subgroup_size=100000):\n",
    "    \"\"\"Performs beam search with a constraint to avoid adding similar descriptors.\n",
    "\n",
    "    Args:\n",
    "        data: The dataset to analyze.\n",
    "        targets_baseline: The baseline target values for comparison.\n",
    "        column_names: The names of the columns in the dataset.\n",
    "        beam_width: The number of descriptors to keep at each depth level.\n",
    "        beam_depth: The maximum depth of the beam search.\n",
    "        nr_bins: The number of bins to create for numeric attributes.\n",
    "        nr_saved: The number of best results to save.\n",
    "        subgroup_size: The minimum size of a subgroup to consider.\n",
    "        target: The target variable for which to evaluate subgroups.\n",
    "        types: The types of each column in the dataset (e.g., numeric, binary, nominal).\n",
    "        window_size: The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        A list of the best descriptor sets found during the search, ensuring no similar descriptors.\n",
    "    \"\"\"\n",
    "    # Create dictionaries for indexing columns by name and vice versa\n",
    "    index_col_dict = {i: col for i, col in enumerate(column_names)}\n",
    "    col_index_dict = {col: i for i, col in enumerate(column_names)}\n",
    "    target_ind = column_names.index(target)  # Get index of the target column\n",
    "    att_indices = list(range(len(column_names)))  # Create a list of all indices\n",
    "    att_indices.remove(target_ind)  # Remove the target index from attribute indices\n",
    "\n",
    "    # Prepare data windows with rolling windows for the target variable\n",
    "    data_windows = []\n",
    "    for row in data:\n",
    "        new_row = row[:]  # Create a copy of the row\n",
    "        new_row[target_ind] = make_rolling_windows(row[target_ind], window_size)  # Apply rolling window\n",
    "        data_windows.append(new_row)  # Add the new row to data_windows\n",
    "\n",
    "    # Update the data and baseline targets to use rolling windows\n",
    "    data = data_windows\n",
    "    targets_baseline = make_rolling_windows(targets_baseline, window_size)\n",
    "\n",
    "    # Initialize a deque for the beam search and a priority queue for results\n",
    "    beam_queue = deque([()])  # Start with an empty seed\n",
    "    results = PriorityQueue(nr_saved)  # Queue to hold the best results\n",
    "    results.put((0, [(0, 0, 0)], [-1],0))  # Add a dummy descriptor to initialize\n",
    "    cover_weight = 0.5\n",
    "    max_quality = 1\n",
    "    # Iterate through each depth of the beam search\n",
    "    for depth in range(beam_depth):\n",
    "        beam = PriorityQueue(beam_width)  # Initialize a new beam for this depth\n",
    "\n",
    "        # While there are seeds in the beam queue\n",
    "        while bool(beam_queue):\n",
    "            seed = beam_queue.popleft()  # Get the next seed descriptor\n",
    "            descriptor_set = refin(seed, data, types, nr_bins, att_indices, index_col_dict, col_index_dict)  # Refine descriptors based on seed\n",
    "\n",
    "            # Evaluate each descriptor set generated\n",
    "            for descriptor in descriptor_set:\n",
    "                subgroup, index_list = extract_subgroup_index(descriptor, data, col_index_dict)  # Extract subgroup for the current descriptor\n",
    "                if len(subgroup) >= subgroup_size and len(subgroup) < max_subgroup_size:  # Ensure subgroup is large enough and descriptor is not similar\n",
    "                    targets_subgroup = [i[target_ind] for i in subgroup]  # Extract target values for the subgroup\n",
    "                    quality_result = quality_measure(targets_subgroup, targets_baseline)  # Calculate quality measure\n",
    "                    cover_score = calc_cover_score(index_list, results)\n",
    "                    final_score = (cover_weight * (cover_score*quality_result)) + ((1-cover_weight) * quality_result)\n",
    "                    # print(descriptor)\n",
    "                    # print(final_score, quality_result, cover_score)\n",
    "                    # print('\\n')\n",
    "                    put_item_in_queue(results, final_score, tuple(descriptor), index_list, quality_result)  # Add to results queue\n",
    "                    put_item_in_queue(beam, final_score, tuple(descriptor))  # Add to the current beam\n",
    "\n",
    "        # After processing the beam, update the beam queue with new combinations\n",
    "        while not beam.empty():\n",
    "            new_combination = beam.get()  # Get the highest quality descriptor from the beam\n",
    "            new_combination = new_combination[1]  # Extract the descriptor from the tuple\n",
    "            beam_queue.append(new_combination)  # Add it to the next depth of the beam search\n",
    "\n",
    "    # Compile results into a list and reverse to have the best results first\n",
    "    results_list = []\n",
    "    while not results.empty():\n",
    "        item = results.get()  # Get items from the results queue\n",
    "        results_list.append(item)  # Add to the results list\n",
    "    results_list.reverse()  # Reverse the list to have best results first\n",
    "\n",
    "    return results_list  # Return the list of best descriptor sets\n",
    "\n",
    "def calc_cover_score(new_index_list, results_pq, alpha):\n",
    "    all_result_index_list = get_all_descriptors(results_pq, 2)\n",
    "    all_cover_scores = []\n",
    "    for result_index_list in all_result_index_list:\n",
    "        covered_tuples = [t for t in new_index_list if t in result_index_list]\n",
    "        # if not new_index_list:  # If subgroup G is empty\n",
    "        #     cover_score =  0\n",
    "        # else:\n",
    "        cover_score = alpha ** len(covered_tuples)\n",
    "        all_cover_scores.append(cover_score)\n",
    "        print(all_cover_scores, len(covered_tuples))\n",
    "    return min(all_cover_scores)\n",
    "\n",
    "\n",
    "\n",
    "def calc_cover_score(new_index_list, results_pq, alpha):\n",
    "    all_result_index_list = get_all_descriptors(results_pq, 2)\n",
    "    alpha_scores = []\n",
    "    for index in new_index_list:\n",
    "        count_index = sum(sublist.count(index) for sublist in all_result_index_list)\n",
    "        alpha_scores.append(alpha ** count_index)\n",
    "    cover_score = sum(alpha_scores) / len(new_index_list)\n",
    "    return cover_score\n",
    "\n",
    "\n",
    "def calc_cover_score(new_index_list, results_pq):\n",
    "    all_result_index_list = get_all_descriptors(results_pq, 2)\n",
    "    new_index_set = set(new_index_list)  # Convert to set for faster lookups\n",
    "    size_new_index = len(new_index_set)   # Pre-calculate size\n",
    "    all_cover_scores = []\n",
    "\n",
    "    for result_index_list in all_result_index_list:\n",
    "        result_index_set = set(result_index_list)  # Convert to set\n",
    "        covered_tuples = new_index_set.intersection(result_index_set)  # Get intersection\n",
    "        size_result_index = len(result_index_set)  # Size of result index list\n",
    "        size = max(size_new_index, size_result_index)  # Max size for cover score calculation\n",
    "        cover_score = len(covered_tuples) / size  # Calculate cover score\n",
    "        all_cover_scores.append(cover_score)\n",
    "\n",
    "    return 1 - max(all_cover_scores)\n",
    "\n",
    "\n",
    "def beam_search_with_constraint_descriptor2(data, targets_baseline, column_names, beam_width, beam_depth, nr_bins, nr_saved, subgroup_size, target, types, window_size, max_subgroup_size=100000):\n",
    "    \"\"\"Performs beam search with a constraint to avoid adding similar descriptors.\n",
    "\n",
    "    Args:\n",
    "        data: The dataset to analyze.\n",
    "        targets_baseline: The baseline target values for comparison.\n",
    "        column_names: The names of the columns in the dataset.\n",
    "        beam_width: The number of descriptors to keep at each depth level.\n",
    "        beam_depth: The maximum depth of the beam search.\n",
    "        nr_bins: The number of bins to create for numeric attributes.\n",
    "        nr_saved: The number of best results to save.\n",
    "        subgroup_size: The minimum size of a subgroup to consider.\n",
    "        target: The target variable for which to evaluate subgroups.\n",
    "        types: The types of each column in the dataset (e.g., numeric, binary, nominal).\n",
    "        window_size: The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        A list of the best descriptor sets found during the search, ensuring no similar descriptors.\n",
    "    \"\"\"\n",
    "    # Create dictionaries for indexing columns by name and vice versa\n",
    "    index_col_dict = {i: col for i, col in enumerate(column_names)}\n",
    "    col_index_dict = {col: i for i, col in enumerate(column_names)}\n",
    "    target_ind = column_names.index(target)  # Get index of the target column\n",
    "    att_indices = list(range(len(column_names)))  # Create a list of all indices\n",
    "    att_indices.remove(target_ind)  # Remove the target index from attribute indices\n",
    "\n",
    "    # Prepare data windows with rolling windows for the target variable\n",
    "    data_windows = []\n",
    "    for row in data:\n",
    "        new_row = row[:]  # Create a copy of the row\n",
    "        new_row[target_ind] = make_rolling_windows(row[target_ind], window_size)  # Apply rolling window\n",
    "        data_windows.append(new_row)  # Add the new row to data_windows\n",
    "\n",
    "    # Update the data and baseline targets to use rolling windows\n",
    "    data = data_windows\n",
    "    targets_baseline = make_rolling_windows(targets_baseline, window_size)\n",
    "\n",
    "    # Initialize a deque for the beam search and a priority queue for results\n",
    "    beam_queue = deque([()])  # Start with an empty seed\n",
    "    results = PriorityQueue(nr_saved)  # Queue to hold the best results\n",
    "    results.put((0, [(0, 0, 0)], 0, 0))  # Add a dummy descriptor to initialize\n",
    "\n",
    "    # Iterate through each depth of the beam search\n",
    "    for depth in range(beam_depth):\n",
    "        beam = PriorityQueue(beam_width)  # Initialize a new beam for this depth\n",
    "\n",
    "        # While there are seeds in the beam queue\n",
    "        while bool(beam_queue):\n",
    "            seed = beam_queue.popleft()  # Get the next seed descriptor\n",
    "            descriptor_set = refin(seed, data, types, nr_bins, att_indices, index_col_dict, col_index_dict)  # Refine descriptors based on seed\n",
    "\n",
    "            # Evaluate each descriptor set generated\n",
    "            for descriptor in descriptor_set:\n",
    "                subgroup = extract_subgroup(descriptor, data, col_index_dict)  # Extract subgroup for the current descriptor\n",
    "                if len(subgroup) >= subgroup_size and len(subgroup) < max_subgroup_size:  # Ensure subgroup is large enough and descriptor is not similar\n",
    "                    targets_subgroup = [i[target_ind] for i in subgroup]  # Extract target values for the subgroup\n",
    "                    quality_result = quality_measure(targets_subgroup, targets_baseline)  # Calculate quality measure\n",
    "                    if not descriptors_similar_paper3(quality_result, descriptor, results):\n",
    "                        put_item_in_queue(results, quality_result, tuple(descriptor), len(subgroup))  # Add to results queue\n",
    "                        put_item_in_queue(beam, quality_result, tuple(descriptor))  # Add to the current beam\n",
    "\n",
    "        # After processing the beam, update the beam queue with new combinations\n",
    "        while not beam.empty():\n",
    "            new_combination = beam.get()  # Get the highest quality descriptor from the beam\n",
    "            new_combination = new_combination[1]  # Extract the descriptor from the tuple\n",
    "            beam_queue.append(new_combination)  # Add it to the next depth of the beam search\n",
    "\n",
    "    dominance_pruning(results, subgroup_size, col_index_dict, targets_baseline, data, target_ind)\n",
    "    # Compile results into a list and reverse to have the best results first\n",
    "    results_list = []\n",
    "    while not results.empty():\n",
    "        item = results.get()  # Get items from the results queue\n",
    "        results_list.append(item)  # Add to the results list\n",
    "    results_list.reverse()  # Reverse the list to have best results first\n",
    "\n",
    "    return results_list  # Return the list of best descriptor sets\n",
    "\n",
    "def are_descriptors_similar2(quality, descriptor1, pq):\n",
    "    \"\"\"Check if the given descriptor is similar to any descriptors in the priority queue.\n",
    "\n",
    "    Args:\n",
    "        descriptor1: The first descriptor to compare (a list of (metric, value, func) tuples).\n",
    "        pq: A priority queue containing other descriptors.\n",
    "\n",
    "    Returns:\n",
    "        True if a similar descriptor is found in the queue, False otherwise.\n",
    "    \"\"\"\n",
    "    tolerance = 0.1 # Tolerance range for numeric comparison\n",
    "    desc1_dict = {metric: (value, func) for metric, value, func in descriptor1}  # Convert descriptor1 to a dictionary\n",
    "    descriptor_list = get_all_descriptors(pq, 1)\n",
    "    quality_list = get_all_descriptors(pq, 0)\n",
    "    #print(quality_list)\n",
    "    quality_diff = min([abs(quality - q) for q in quality_list])\n",
    "    if quality_diff > 5:\n",
    "        return False\n",
    "    match_count=0\n",
    "    # Iterate through each descriptor in the list\n",
    "    for descriptor2 in descriptor_list:\n",
    "        desc2_dict = {metric: (value, func) for metric, value, func in descriptor2}  # Convert descriptor2 to a dictionary\n",
    "\n",
    "        # If the length of descriptors doesn't match, skip\n",
    "        if len(desc1_dict) != len(desc2_dict):\n",
    "            continue\n",
    "\n",
    "        all_metrics_match = True  # Flag to track if all metrics match\n",
    "\n",
    "        # Check each metric in descriptor1\n",
    "        for metric in desc1_dict:\n",
    "            if match_count>=2:\n",
    "                return True\n",
    "            if metric in desc2_dict:\n",
    "                value1, func1 = desc1_dict[metric]\n",
    "                value2, func2 = desc2_dict[metric]\n",
    "\n",
    "                # Check if the functions are the same\n",
    "                if func1 != func2:\n",
    "                    all_metrics_match = False\n",
    "                    continue\n",
    "\n",
    "                # Check if numeric values are within tolerance range\n",
    "                if (not isinstance(value1, str)) and abs(value1 - value2) > abs(tolerance * value1):\n",
    "                    all_metrics_match = False\n",
    "                    continue\n",
    "\n",
    "                # For strings, check if values are exactly the same\n",
    "                if isinstance(value1, str) and value1 != value2:\n",
    "                    all_metrics_match = False\n",
    "                    continue\n",
    "                else:\n",
    "                    match_count+=1\n",
    "                    all_metrics_match=True\n",
    "            else:\n",
    "                # If metric in descriptor1 is not in descriptor2, they are not similar\n",
    "                all_metrics_match = False\n",
    "                continue\n",
    "\n",
    "        # If all metrics match, return True (descriptors are similar)\n",
    "        if all_metrics_match and match_count>=2:\n",
    "            return True\n",
    "\n",
    "    # If no similar descriptors are found, return False\n",
    "    return False\n",
    "\n",
    "def descriptors_similar_paper(quality, descriptor1, pq):\n",
    "    # Remove the single descriptor early exit if needed\n",
    "    if len(descriptor1) == 1:\n",
    "        return False\n",
    "\n",
    "    tolerance = 0.1  # 10% tolerance\n",
    "    desc1_dict = {metric: (value, func) for metric, value, func in descriptor1}\n",
    "    descriptor_list = get_all_descriptors(pq, 1)\n",
    "    quality_list = get_all_descriptors(pq, 0)\n",
    "    if min(abs(quality - q) for q in quality_list) > 0.5:\n",
    "        return False\n",
    "\n",
    "\n",
    "    # Compare against each descriptor in the queue\n",
    "    for descriptor2 in descriptor_list:\n",
    "        desc2_dict = {metric: (value, func) for metric, value, func in descriptor2}\n",
    "\n",
    "        match_count = 0\n",
    "        total_conditions = len(desc1_dict)-1\n",
    "\n",
    "        for metric, (value1, func1) in desc1_dict.items():\n",
    "            if metric not in desc2_dict:\n",
    "                continue  # If a metric is missing, no need to continue\n",
    "\n",
    "            value2, func2 = desc2_dict[metric]\n",
    "\n",
    "            # Function mismatch, skip this descriptor\n",
    "            if func1 != func2:\n",
    "                continue\n",
    "\n",
    "            # Numeric comparison within tolerance\n",
    "            if isinstance(value1, (int, float)) and isinstance(value2, (int, float)):\n",
    "                relative_tolerance = tolerance * max(abs(value1), abs(value2))\n",
    "                if abs(value1 - value2) > relative_tolerance:\n",
    "                    continue  # Values out of tolerance range\n",
    "\n",
    "            # String comparison for non-numeric values\n",
    "            elif isinstance(value1, str) and value1 != value2:\n",
    "                continue  # String values don't match\n",
    "\n",
    "            match_count += 1\n",
    "\n",
    "            # Require all conditions to match\n",
    "            if match_count == total_conditions:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def descriptors_similar_paper2(quality, descriptor1, pq):\n",
    " \n",
    "\n",
    "    # if len(descriptor1) == 1:\n",
    "    #     return False\n",
    "\n",
    "    tolerance = 0.1\n",
    "    desc1_dict = {metric: (value, func) for metric, value, func in descriptor1}\n",
    "    descriptor_list = get_all_descriptors(pq, 1)\n",
    "    quality_list = get_all_descriptors(pq, 0)\n",
    "    #print(descriptor_list)\n",
    "    # Early exit if quality difference exceeds threshold\n",
    "    # if min(abs(quality - q) for q in quality_list) > 1000:\n",
    "    #     return False\n",
    "    try:\n",
    "        if desc1_dict['country'][0] =='Japan':\n",
    "            print(desc1_dict)\n",
    "    except:\n",
    "        pass\n",
    "    # Compare against each descriptor in the queue\n",
    "    for descriptor2 in descriptor_list:\n",
    "\n",
    "        desc2_dict = {metric: (value, func) for metric, value, func in descriptor2}\n",
    "        #print(desc2_dict)\n",
    "        match_count = 0\n",
    "        try:\n",
    "            if desc1_dict['country'][0] =='Japan':\n",
    "                print(desc2_dict)\n",
    "        except:\n",
    "            pass\n",
    "        for metric, (value1, func1) in desc1_dict.items():\n",
    "            if metric not in desc2_dict:\n",
    "                continue  # If a metric is missing, no need to continue\n",
    "\n",
    "            value2, func2 = desc2_dict[metric]\n",
    "            \n",
    "            # Function mismatch, skip this descriptor\n",
    "            if func1 != func2:\n",
    "                continue\n",
    "\n",
    "            # Numeric comparison within tolerance\n",
    "            if isinstance(value1, (int, float)) and isinstance(value2, (int, float)):\n",
    "                if value1 != value2:\n",
    "                    continue  # Values out of tolerance range\n",
    "\n",
    "            # String comparison for non-numeric values\n",
    "            elif isinstance(value1, str) and value1 != value2:\n",
    "                continue  # String values don't match\n",
    "\n",
    "            match_count += 1\n",
    "\n",
    "            # Early exit when all metrics except 1 match\n",
    "            \n",
    "            if match_count >= len(descriptor1)-1:\n",
    "                try:\n",
    "                    if desc1_dict['country'][0] =='Japan':\n",
    "                        print('true \\n')\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                \n",
    "                return True\n",
    "    \n",
    "    try:\n",
    "        if desc1_dict['country'][0] =='Japan':\n",
    "            print('false',len(descriptor_list), '\\n')\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "@time_function\n",
    "def dominance_pruning(pq, subgroup_size, col_index_dict, targets_baseline, data, target_ind):\n",
    "    descriptor_list = get_all_descriptors(pq, 1)\n",
    "    quality_list = get_all_descriptors(pq, 0)\n",
    "    for org_quality, org_descriptor in zip(quality_list, descriptor_list):\n",
    "        \n",
    "        for cc in range(len(org_descriptor)-1):  # Use a while loop as the length of the list may change during pruning\n",
    "            \n",
    "            temp_subgroup = org_descriptor[:cc] + org_descriptor[cc+1:]  # Remove the current condition\n",
    "            subgroup = extract_subgroup(temp_subgroup, data, col_index_dict)  # Extract subgroup for the current descriptor\n",
    "            if len(subgroup) >= subgroup_size:  # Ensure subgroup is large enough and descriptor is not similar\n",
    "                targets_subgroup = [j[target_ind] for j in subgroup]  # Extract target values for the subgroup\n",
    "                quality_result = quality_measure(targets_subgroup, targets_baseline)  # Calculate quality measure\n",
    "                if not descriptors_similar_paper3(quality_result, temp_subgroup, pq) and quality_result > org_quality:\n",
    "                    put_item_in_queue(pq, quality_result, tuple(temp_subgroup), len(subgroup))\n",
    "\n",
    "\n",
    "def descriptors_similar_paper3(quality, descriptor1, pq):\n",
    "\n",
    "    if len(descriptor1) == 1:\n",
    "        return False\n",
    "\n",
    "    desc1_dict = {metric: (value, func) for metric, value, func in descriptor1}\n",
    "    descriptor_list = get_all_descriptors(pq, 1)\n",
    "    quality_list = get_all_descriptors(pq, 0)\n",
    "\n",
    "    # Early exit if quality difference exceeds threshold\n",
    "    if min(abs(quality - q) for q in quality_list) > 0.5:\n",
    "        return False\n",
    "\n",
    "    # Compare against each descriptor in the queue\n",
    "    for descriptor2 in descriptor_list:\n",
    "\n",
    "        desc2_dict = {metric: (value, func) for metric, value, func in descriptor2}\n",
    "\n",
    "        match_count = 0\n",
    "\n",
    "        for metric, (value1, func1) in desc1_dict.items():\n",
    "            if metric not in desc2_dict:\n",
    "                continue  # If a metric is missing, no need to continue\n",
    "\n",
    "            value2, func2 = desc2_dict[metric]\n",
    "\n",
    "            # Function mismatch, skip this descriptor\n",
    "            if func1 != func2:\n",
    "                continue\n",
    "\n",
    "            # Numeric comparison within tolerance\n",
    "            if isinstance(value1, (int, float)) and isinstance(value2, (int, float)):\n",
    "                if value1 != value2:\n",
    "                    continue  # Values out of tolerance range\n",
    "\n",
    "            # String comparison for non-numeric values\n",
    "            elif isinstance(value1, str) and value1 != value2:\n",
    "                continue  # String values don't match\n",
    "\n",
    "            match_count += 1\n",
    "\n",
    "            # Early exit when all metrics except 1 match\n",
    "            if match_count == len(desc1_dict)-1:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# Helper function to check if two metrics match with tolerance\n",
    "def metrics_match(metric1, metric2):\n",
    "    value1, func1 = metric1\n",
    "    value2, func2 = metric2\n",
    "\n",
    "    # If functions are different, metrics don't match\n",
    "    if func1 != func2:\n",
    "        return False\n",
    "\n",
    "    # If both values are numbers, compare within tolerance\n",
    "    if value1 != value2:\n",
    "        return False\n",
    "\n",
    "    # In all other cases, no match\n",
    "    return True\n",
    "    \n",
    "def descriptors_similar_paper3(quality, descriptor1, pq):\n",
    "    # If descriptor1 has only one metric, exit early\n",
    "    if len(descriptor1) == 1:\n",
    "        return False\n",
    "\n",
    "    total_conditions = len(descriptor1) - 1\n",
    "    descriptor_list = get_all_descriptors(pq, 1)\n",
    "    quality_list = get_all_descriptors(pq, 0)\n",
    "\n",
    "    # Early exit based on quality difference\n",
    "    if min(abs(quality - q) for q in quality_list) > 0.25:\n",
    "        return False\n",
    "\n",
    "    # Compare descriptor1 against all other descriptors in pq\n",
    "    for descriptor2 in descriptor_list:\n",
    "        match_count = 0\n",
    "\n",
    "        # Create a copy of descriptor2 to mark used metrics\n",
    "        remaining_descriptor2 = list(descriptor2)\n",
    "\n",
    "        # Compare each metric in descriptor1 to all available metrics in descriptor2\n",
    "        for metric1_name, value1, func1 in descriptor1:\n",
    "            matched = False\n",
    "\n",
    "            # Iterate over all metrics in descriptor2 with the same name\n",
    "            for i, (metric2_name, value2, func2) in enumerate(remaining_descriptor2):\n",
    "                if metric1_name == metric2_name:\n",
    "                    if metrics_match((value1, func1), (value2, func2)):\n",
    "                        matched = True\n",
    "                        # Mark this metric as used by removing it from remaining metrics\n",
    "                        remaining_descriptor2.pop(i)\n",
    "                        break\n",
    "\n",
    "            if matched:\n",
    "                match_count += 1\n",
    "\n",
    "            # If all but one metrics match, descriptors are considered similar\n",
    "            if match_count >= total_conditions:\n",
    "                return True\n",
    "\n",
    "    # If no matching descriptor is found, return False\n",
    "    return False\n",
    "def dominance_pruning(pq, subgroup_size, col_index_dict, targets_baseline, data, target_ind):\n",
    "    descriptor_list = get_all_descriptors(pq, 1)\n",
    "    quality_list = get_all_descriptors(pq, 0)\n",
    "    for org_quality, org_descriptor in zip(quality_list, descriptor_list):\n",
    "\n",
    "        for cc in range(len(org_descriptor)-1):  # Use a while loop as the length of the list may change during pruning\n",
    "\n",
    "            temp_subgroup = org_descriptor[:cc] + org_descriptor[cc+1:]  # Remove the current condition\n",
    "            subgroup = extract_subgroup(temp_subgroup, data, col_index_dict)  # Extract subgroup for the current descriptor\n",
    "            if len(subgroup) >= subgroup_size:  # Ensure subgroup is large enough and descriptor is not similar\n",
    "                targets_subgroup = [j[target_ind] for j in subgroup]  # Extract target values for the subgroup\n",
    "                quality_result = quality_measure(targets_subgroup, targets_baseline)  # Calculate quality measure\n",
    "                if not descriptors_similar_paper3(quality_result, temp_subgroup, pq) and quality_result > org_quality:\n",
    "                    put_item_in_queue(pq, quality_result, tuple(temp_subgroup), len(subgroup))"
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:29:57.520435Z",
     "start_time": "2024-10-10T12:28:57.745089Z"
    }
   },
   "cell_type": "code",
   "source": "stock_df = make_growth_target_df('datasets/stock_data_for_emm.pkl')",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:29:57.676881Z",
     "start_time": "2024-10-10T12:29:57.634955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#stock_df.drop(['index'], inplace=True, axis=1)\n",
    "stock_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             country                        industry currency  \\\n",
       "0             France             Aerospace & Defense      EUR   \n",
       "1            Germany            SoftwareApplication      EUR   \n",
       "2              Italy                   Entertainment      EUR   \n",
       "3              Italy                  Packaged Foods      EUR   \n",
       "4     United Kingdom  Other Precious Metals & Mining      EUR   \n",
       "...              ...                             ...      ...   \n",
       "9774           Japan    Electrical Equipment & Parts      JPY   \n",
       "9775           Japan   Business Equipment & Supplies      JPY   \n",
       "9776           Japan  Electronic Gaming & Multimedia      JPY   \n",
       "9777           Japan           Electronic Components      JPY   \n",
       "9778           Japan              Auto Manufacturers      JPY   \n",
       "\n",
       "     exchangeTimezoneName exchange                  sector  \\\n",
       "0            Europe/Paris      PAR             Industrials   \n",
       "1           Europe/Berlin      GER              Technology   \n",
       "2             Europe/Rome      MIL  Communication Services   \n",
       "3             Europe/Rome      MIL      Consumer Defensive   \n",
       "4           Europe/Berlin      FRA         Basic Materials   \n",
       "...                   ...      ...                     ...   \n",
       "9774        Europe/London      LSE             Industrials   \n",
       "9775        Europe/London      LSE             Industrials   \n",
       "9776        Europe/London      LSE  Communication Services   \n",
       "9777        Europe/London      LSE              Technology   \n",
       "9778        Europe/London      LSE       Consumer Cyclical   \n",
       "\n",
       "      averageVolume10days  enterpriseToEbitda     marketCap  debtToEquity  \\\n",
       "0                   382.0              11.822  5.750674e+07        50.783   \n",
       "1                  8329.0              33.294  1.241838e+09        32.492   \n",
       "2                   330.0             -21.050  2.849466e+07       181.181   \n",
       "3                  3831.0               8.794  5.971590e+07        68.513   \n",
       "4                   108.0               1.402  2.123667e+08        81.212   \n",
       "...                   ...                 ...           ...           ...   \n",
       "9774               4893.0               6.287  2.079737e+10        10.654   \n",
       "9775               1940.0               5.531  5.086319e+09        35.268   \n",
       "9776               3530.0               7.976  6.297095e+09        18.311   \n",
       "9777                350.0               7.200  1.774490e+09         1.943   \n",
       "9778              72760.0              12.413  1.971894e+11       102.678   \n",
       "\n",
       "      fullTimeEmployees                                      growth_target  \n",
       "0                1102.0  [0.0, 1.17, 2.41, 0.41, 2.65, -1.39, -7.24, -4...  \n",
       "1                 650.0  [0.0, -1.84, 17.01, 3.7, -8.24, 8.01, -3.6, 4....  \n",
       "2                  34.0  [0.0, -7.96, -2.61, 0.89, 13.94, -4.85, -6.12,...  \n",
       "3                 232.0  [0.0, -3.39, 0.58, -10.17, 11.33, -2.91, 2.1, ...  \n",
       "4                3474.0  [0.0, 8.5, -15.79, 5.28, 2.24, -1.94, 7.5, -1....  \n",
       "...                 ...                                                ...  \n",
       "9774           145696.0  [0.0, 1.08, 10.44, -11.75, -11.15, 7.96, -9.17...  \n",
       "9775            78360.0  [0.0, 5.82, 1.71, 7.84, -10.55, 3.58, -7.94, 2...  \n",
       "9776             4894.0  [0.0, 6.5, 0.0, -10.85, -1.95, -3.62, -3.95, 9...  \n",
       "9777             1297.0  [0.0, 0.0, 0.0, 0.0, 18.86, 0.0, 0.0, 0.0, 10....  \n",
       "9778           376971.0  [0.0, 2.08, 5.28, -3.71, -7.07, 5.43, -4.35, 4...  \n",
       "\n",
       "[9779 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>industry</th>\n",
       "      <th>currency</th>\n",
       "      <th>exchangeTimezoneName</th>\n",
       "      <th>exchange</th>\n",
       "      <th>sector</th>\n",
       "      <th>averageVolume10days</th>\n",
       "      <th>enterpriseToEbitda</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>debtToEquity</th>\n",
       "      <th>fullTimeEmployees</th>\n",
       "      <th>growth_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Paris</td>\n",
       "      <td>PAR</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>382.0</td>\n",
       "      <td>11.822</td>\n",
       "      <td>5.750674e+07</td>\n",
       "      <td>50.783</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[0.0, 1.17, 2.41, 0.41, 2.65, -1.39, -7.24, -4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>SoftwareApplication</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Berlin</td>\n",
       "      <td>GER</td>\n",
       "      <td>Technology</td>\n",
       "      <td>8329.0</td>\n",
       "      <td>33.294</td>\n",
       "      <td>1.241838e+09</td>\n",
       "      <td>32.492</td>\n",
       "      <td>650.0</td>\n",
       "      <td>[0.0, -1.84, 17.01, 3.7, -8.24, 8.01, -3.6, 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Rome</td>\n",
       "      <td>MIL</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>330.0</td>\n",
       "      <td>-21.050</td>\n",
       "      <td>2.849466e+07</td>\n",
       "      <td>181.181</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[0.0, -7.96, -2.61, 0.89, 13.94, -4.85, -6.12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Packaged Foods</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Rome</td>\n",
       "      <td>MIL</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>3831.0</td>\n",
       "      <td>8.794</td>\n",
       "      <td>5.971590e+07</td>\n",
       "      <td>68.513</td>\n",
       "      <td>232.0</td>\n",
       "      <td>[0.0, -3.39, 0.58, -10.17, 11.33, -2.91, 2.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Other Precious Metals &amp; Mining</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Berlin</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.402</td>\n",
       "      <td>2.123667e+08</td>\n",
       "      <td>81.212</td>\n",
       "      <td>3474.0</td>\n",
       "      <td>[0.0, 8.5, -15.79, 5.28, 2.24, -1.94, 7.5, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9774</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Electrical Equipment &amp; Parts</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>4893.0</td>\n",
       "      <td>6.287</td>\n",
       "      <td>2.079737e+10</td>\n",
       "      <td>10.654</td>\n",
       "      <td>145696.0</td>\n",
       "      <td>[0.0, 1.08, 10.44, -11.75, -11.15, 7.96, -9.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9775</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Business Equipment &amp; Supplies</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.086319e+09</td>\n",
       "      <td>35.268</td>\n",
       "      <td>78360.0</td>\n",
       "      <td>[0.0, 5.82, 1.71, 7.84, -10.55, 3.58, -7.94, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Electronic Gaming &amp; Multimedia</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>7.976</td>\n",
       "      <td>6.297095e+09</td>\n",
       "      <td>18.311</td>\n",
       "      <td>4894.0</td>\n",
       "      <td>[0.0, 6.5, 0.0, -10.85, -1.95, -3.62, -3.95, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9777</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Electronic Components</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Technology</td>\n",
       "      <td>350.0</td>\n",
       "      <td>7.200</td>\n",
       "      <td>1.774490e+09</td>\n",
       "      <td>1.943</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 18.86, 0.0, 0.0, 0.0, 10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Auto Manufacturers</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>72760.0</td>\n",
       "      <td>12.413</td>\n",
       "      <td>1.971894e+11</td>\n",
       "      <td>102.678</td>\n",
       "      <td>376971.0</td>\n",
       "      <td>[0.0, 2.08, 5.28, -3.71, -7.07, 5.43, -4.35, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9779 rows  12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:29:57.785551Z",
     "start_time": "2024-10-10T12:29:57.773585Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:29:57.910217Z",
     "start_time": "2024-10-10T12:29:57.882293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = stock_df.values.tolist()\n",
    "column_names = list(stock_df.columns)\n",
    "beam_width = 10\n",
    "beam_depth = 3\n",
    "nr_bins = 8\n",
    "nr_saved = 10\n",
    "subgroup_size = len(data)*0.05\n",
    "target = 'growth_target'\n",
    "window_size = 5"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:29:58.095389Z",
     "start_time": "2024-10-10T12:29:58.034142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_ind = column_names.index(target)\n",
    "all_time_series = [i[target_ind] for i in data]\n",
    "all_time_series = np.array(all_time_series)\n",
    "targets_baseline = np.mean(all_time_series, axis=0)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:41:42.929632Z",
     "start_time": "2024-10-10T14:41:42.903745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "att_indices = list(range(0, len(column_names)))\n",
    "att_indices.remove(target_ind)\n",
    "att_columns = [column_names[i] for i in att_indices]\n",
    "types = categorize_columns_in_order(stock_df, att_columns)"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:27:52.030146Z",
     "start_time": "2024-10-10T15:27:27.278537Z"
    }
   },
   "cell_type": "code",
   "source": "results  = beam_search_with_constraint_descriptor2(data, targets_baseline, column_names, beam_width, beam_depth, nr_bins, nr_saved, subgroup_size, target, types, window_size)\n",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:27:52.061064Z",
     "start_time": "2024-10-10T15:27:52.040120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for r in results:\n",
    "    print(r[:3])\n",
    "    print('\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.274882219354637, (('country', 'Japan', <function eq at 0x0000021B58D65B40>), ('enterpriseToEbitda', -1.044, <function gt at 0x0000021B58D67D00>), ('marketCap', 1977535730.11456, <function gt at 0x0000021B58D67D00>)), 491)\n",
      "\n",
      "\n",
      "(6.803150219406607, (('fullTimeEmployees', 7686.0, <function gt at 0x0000021B58D67D00>), ('country', 'Japan', <function eq at 0x0000021B58D65B40>)), 616)\n",
      "\n",
      "\n",
      "(6.650918653291399, (('country', 'Japan', <function eq at 0x0000021B58D65B40>), ('marketCap', 12953903104.0, <function leeq at 0x0000021B58D67EB0>), ('fullTimeEmployees', 1817.0, <function gt at 0x0000021B58D67D00>)), 575)\n",
      "\n",
      "\n",
      "(6.205676446380705, (('country', 'Japan', <function eq at 0x0000021B58D65B40>), ('enterpriseToEbitda', -1.044, <function gt at 0x0000021B58D67D00>)), 656)\n",
      "\n",
      "\n",
      "(5.8773758485413, (('fullTimeEmployees', 46000.0, <function gt at 0x0000021B58D67D00>), ('enterpriseToEbitda', 9.382, <function leeq at 0x0000021B58D67EB0>), ('enterpriseToEbitda', 8.486, <function leeq at 0x0000021B58D67EB0>)), 535)\n",
      "\n",
      "\n",
      "(5.483318178782075, (('fullTimeEmployees', 46000.0, <function gt at 0x0000021B58D67D00>), ('enterpriseToEbitda', 9.382, <function leeq at 0x0000021B58D67EB0>)), 611)\n",
      "\n",
      "\n",
      "(5.1886977129942675, (('marketCap', 28408813568.0, <function gt at 0x0000021B58D67D00>), ('enterpriseToEbitda', 16.41, <function leeq at 0x0000021B58D67EB0>)), 764)\n",
      "\n",
      "\n",
      "(4.922588652282997, (('fullTimeEmployees', 7686.0, <function gt at 0x0000021B58D67D00>), ('sector', 'Industrials', <function eq at 0x0000021B58D65B40>)), 870)\n",
      "\n",
      "\n",
      "(4.89408652586778, (('marketCap', 28408813568.0, <function gt at 0x0000021B58D67D00>), ('averageVolume10days', 8.0, <function gt at 0x0000021B58D67D00>)), 1067)\n",
      "\n",
      "\n",
      "(4.499988267243778, (('fullTimeEmployees', 46000.0, <function gt at 0x0000021B58D67D00>), ('averageVolume10days', 0.0, <function gt at 0x0000021B58D67D00>)), 1061)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:15:22.635061Z",
     "start_time": "2024-10-10T12:15:22.599159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res=0\n",
    "match_count = 0\n",
    "tolerance=0.1\n",
    "desc1_dict = { 'country' : ('japan', eq), 'p': (-1.04, gt), 'q': (2, leeq)}\n",
    "desc2_dict = { 'country' : ('japan', eq), 'p': (-1.04, gt), 'q': (10, leeq)}\n",
    "for metric, (value1, func1) in desc1_dict.items():\n",
    "    if metric not in desc2_dict:\n",
    "        continue  # If a metric is missing, no need to continue\n",
    "\n",
    "    value2, func2 = desc2_dict[metric]\n",
    "\n",
    "    # Function mismatch, skip this descriptor\n",
    "    if func1 != func2:\n",
    "        continue\n",
    "\n",
    "    # Numeric comparison within tolerance\n",
    "    if isinstance(value1, (int, float)) and isinstance(value2, (int, float)):\n",
    "        if abs(abs(value1) - abs(value2)) > abs(tolerance * value1):\n",
    "            continue  # Values out of tolerance range\n",
    "\n",
    "    # String comparison for non-numeric values\n",
    "    elif isinstance(value1, str) and value1 != value2:\n",
    "        print(value1, value2, '\\n')\n",
    "        continue  # String values don't match\n",
    "\n",
    "    match_count += 1\n",
    "\n",
    "    # Early exit when all metrics except 1 match\n",
    "    if match_count >= 2:\n",
    "\n",
    "        res=True\n",
    "res"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:10:14.437454Z",
     "start_time": "2024-10-10T11:10:14.418474Z"
    }
   },
   "cell_type": "code",
   "source": "from beam_search_module import beam_search_with_constraint_paper",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T11:11:25.630526Z",
     "start_time": "2024-10-10T11:10:14.991257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = beam_search_with_constraint_paper(data, targets_baseline, column_names, beam_width, beam_depth, nr_bins,\n",
    "                                                  nr_saved, subgroup_size, target, types, window_size)\n",
    "\n",
    "for r in results:\n",
    "    print(r[:3])\n",
    "    print('\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.509657278408514, (('country', 'Japan', <function eq at 0x000001FFC362EB90>), ('enterpriseToEbitda', -1.044, <function gt at 0x000001FFC362EA70>), ('enterpriseToEbitda', 3.978, <function leeq at 0x000001FFC362E9E0>)), 494)\n",
      "\n",
      "\n",
      "(6.431800142548485, (('country', 'Japan', <function eq at 0x000001FFC362EB90>), ('enterpriseToEbitda', -1.044, <function gt at 0x000001FFC362EA70>), ('enterpriseToEbitda', 7.976, <function leeq at 0x000001FFC362E9E0>)), 575)\n",
      "\n",
      "\n",
      "(6.205676446380705, (('country', 'Japan', <function eq at 0x000001FFC362EB90>), ('enterpriseToEbitda', -1.044, <function gt at 0x000001FFC362EA70>)), 656)\n",
      "\n",
      "\n",
      "(6.035047292325761, (('country', 'Japan', <function eq at 0x000001FFC362EB90>), ('enterpriseToEbitda', -1.044, <function gt at 0x000001FFC362EA70>), ('enterpriseToEbitda', -0.356, <function gt at 0x000001FFC362EA70>)), 573)\n",
      "\n",
      "\n",
      "(5.9640679219777635, (('country', 'Japan', <function eq at 0x000001FFC362EB90>), ('enterpriseToEbitda', -1.044, <function gt at 0x000001FFC362EA70>), ('enterpriseToEbitda', 0.268, <function gt at 0x000001FFC362EA70>)), 491)\n",
      "\n",
      "\n",
      "(5.773707403771755, (('marketCap', 28408813568.0, <function gt at 0x000001FFC362EA70>), ('marketCap', 195621847040.0, <function leeq at 0x000001FFC362E9E0>), ('averageVolume10days', 1944.0, <function gt at 0x000001FFC362EA70>)), 534)\n",
      "\n",
      "\n",
      "(5.670155231271532, (('marketCap', 28408813568.0, <function gt at 0x000001FFC362EA70>), ('marketCap', 117536301056.0, <function leeq at 0x000001FFC362E9E0>), ('averageVolume10days', 329.0, <function gt at 0x000001FFC362EA70>)), 573)\n",
      "\n",
      "\n",
      "(5.663785340668793, (('marketCap', 28408813568.0, <function gt at 0x000001FFC362EA70>), ('marketCap', 117536301056.0, <function leeq at 0x000001FFC362E9E0>), ('fullTimeEmployees', 18201.0, <function gt at 0x000001FFC362EA70>)), 684)\n",
      "\n",
      "\n",
      "(5.642104748988323, (('marketCap', 28408813568.0, <function gt at 0x000001FFC362EA70>), ('marketCap', 83129532416.0, <function leeq at 0x000001FFC362E9E0>), ('fullTimeEmployees', 16815.0, <function gt at 0x000001FFC362EA70>)), 571)\n",
      "\n",
      "\n",
      "(5.639128921789861, (('marketCap', 28408813568.0, <function gt at 0x000001FFC362EA70>), ('marketCap', 117536301056.0, <function leeq at 0x000001FFC362E9E0>), ('fullTimeEmployees', 31000.0, <function gt at 0x000001FFC362EA70>)), 572)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def descriptors_similar_paper(quality, descriptor1, pq):\n",
    "    # Remove the single descriptor early exit if needed\n",
    "    if len(descriptor1) == 1:\n",
    "        return False\n",
    "\n",
    "    tolerance = 0.1  # 10% tolerance\n",
    "    desc1_dict = {metric: (value, func) for metric, value, func in descriptor1}\n",
    "    descriptor_list = get_all_descriptors(pq, 1)\n",
    "    quality_list = get_all_descriptors(pq, 0)\n",
    "    if min(abs(quality - q) for q in quality_list) > 0.5:\n",
    "        return False\n",
    "\n",
    "\n",
    "    # Compare against each descriptor in the queue\n",
    "    for descriptor2 in descriptor_list:\n",
    "        desc2_dict = {metric: (value, func) for metric, value, func in descriptor2}\n",
    "\n",
    "        match_count = 0\n",
    "        total_conditions = len(desc1_dict)-1\n",
    "\n",
    "        for metric, (value1, func1) in desc1_dict.items():\n",
    "            if metric not in desc2_dict:\n",
    "                continue  # If a metric is missing, no need to continue\n",
    "\n",
    "            value2, func2 = desc2_dict[metric]\n",
    "\n",
    "            # Function mismatch, skip this descriptor\n",
    "            if func1 != func2:\n",
    "                continue\n",
    "\n",
    "            # Numeric comparison within tolerance\n",
    "            if isinstance(value1, (int, float)) and isinstance(value2, (int, float)):\n",
    "                relative_tolerance = tolerance * max(abs(value1), abs(value2))\n",
    "                if abs(value1 - value2) > relative_tolerance:\n",
    "                    continue  # Values out of tolerance range\n",
    "\n",
    "            # String comparison for non-numeric values\n",
    "            elif isinstance(value1, str) and value1 != value2:\n",
    "                continue  # String values don't match\n",
    "\n",
    "            match_count += 1\n",
    "\n",
    "            # Require all conditions to match\n",
    "            if match_count == total_conditions:\n",
    "                return True\n",
    "\n",
    "    return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
