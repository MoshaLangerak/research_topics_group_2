{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T15:45:45.989952Z",
     "start_time": "2024-10-10T15:45:44.955347Z"
    }
   },
   "source": [
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "from load_data_old import make_growth_target_df\n",
    "import math\n",
    "import time\n",
    "from itertools import combinations\n",
    "\n",
    "def gt(a, b):\n",
    "    \"\"\"Returns True if a is greater than b.\"\"\"\n",
    "    return a > b\n",
    "\n",
    "def leeq(a, b):\n",
    "    \"\"\"Returns True if a is less than or equal to b.\"\"\"\n",
    "    return a <= b\n",
    "\n",
    "def eq(a, b):\n",
    "    \"\"\"Returns True if a is equal to b.\"\"\"\n",
    "    return a == b\n",
    "\n",
    "def neq(a, b):\n",
    "    \"\"\"Returns True if a is not equal to b.\"\"\"\n",
    "    return not eq(a, b)\n",
    "\n",
    "def extract_subgroup(descriptors, data, col_index_dict):\n",
    "    \"\"\"Extracts a subgroup of data that matches all provided descriptors.\n",
    "\n",
    "    Args:\n",
    "        descriptors: A list of descriptors, each containing an attribute name, value, and operator.\n",
    "        data: The dataset from which to extract the subgroup.\n",
    "        col_index_dict: A dictionary mapping column names to their indices.\n",
    "\n",
    "    Returns:\n",
    "        A list of rows from the data that match all descriptors.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for row in data:\n",
    "        check = True\n",
    "        for attribute in descriptors:\n",
    "            att_name, descr_value, operator = attribute  # unpack 3 values from attribute\n",
    "            att_index = col_index_dict[att_name]  # get the index for the attribute\n",
    "            value = operator(row[att_index], descr_value)  # apply the operator\n",
    "\n",
    "            if not value:  # if any descriptor does not match\n",
    "                check = False\n",
    "                break\n",
    "\n",
    "        if check:  # if all descriptors match\n",
    "            result.append(row)  # add the row to the result\n",
    "\n",
    "    return result\n",
    "\n",
    "def refin(seed, data, types, nr_bins, descr_indices, index_col_dict, col_index_dict):\n",
    "    \"\"\"Generates new descriptor sets by refining the seed descriptors.\n",
    "\n",
    "    Args:\n",
    "        seed: The initial set of descriptors to refine.\n",
    "        data: The dataset used for extracting subgroups.\n",
    "        types: The types of each column in the dataset.\n",
    "        nr_bins: The number of bins to create for numeric attributes.\n",
    "        descr_indices: The indices of potential descriptors.\n",
    "        index_col_dict: A dictionary mapping index to column names.\n",
    "        col_index_dict: A dictionary mapping column names to indices.\n",
    "\n",
    "    Returns:\n",
    "        A list of new descriptor sets created by refining the seed.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    used_descr = [col_index_dict[i[0]] for i in seed]  # get used descriptors\n",
    "    not_used_indices = descr_indices[:]  # make a copy of descriptor indices\n",
    "    # Filter out indices that are already used or are numeric types\n",
    "    not_used_indices = [i for i in not_used_indices if i not in used_descr or types[i] == \"numeric\"]\n",
    "\n",
    "    for i in not_used_indices:\n",
    "        aux = list(seed)[:]  # copy the seed\n",
    "\n",
    "        if types[i] == 'numeric':\n",
    "            s = extract_subgroup(seed, data, col_index_dict)  # extract subgroup based on seed\n",
    "            all_values = [float(entry[i]) for entry in s]  # get all values for the numeric attribute\n",
    "            all_values = sorted(all_values)  # sort values\n",
    "            n = len(all_values)\n",
    "            # Create split points for binning\n",
    "            split_points = [all_values[math.floor(j * (n/nr_bins))] for j in range(1, nr_bins)]\n",
    "            for s in split_points:\n",
    "                func1 = leeq\n",
    "                func2 = gt\n",
    "\n",
    "                # Create two new descriptors for each split point\n",
    "                local0 = aux[:]\n",
    "                local0.append((index_col_dict[i], s, func1))  # descriptor for less than or equal\n",
    "                res.append(local0)\n",
    "\n",
    "                local1 = aux[:]\n",
    "                local1.append((index_col_dict[i], s, func2))  # descriptor for greater than\n",
    "                res.append(local1)\n",
    "\n",
    "        elif types[i] == 'binary':\n",
    "            func = eq  # equality function for binary descriptors\n",
    "            local0 = aux[:]\n",
    "            local0.append((index_col_dict[i], 0, func))  # descriptor for value 0\n",
    "            local1 = aux[:]\n",
    "            local1.append((index_col_dict[i], 1, func))  # descriptor for value 1\n",
    "            res.append(local0)\n",
    "            res.append(local1)\n",
    "\n",
    "        else:  # nominal attributes\n",
    "            all_values = [entry[i] for entry in data]  # get all unique values\n",
    "            for j in set(all_values):\n",
    "                func1 = eq\n",
    "                local0 = aux[:]\n",
    "                local0.append((index_col_dict[i], j, func1))  # descriptor for equality\n",
    "                res.append(local0)\n",
    "\n",
    "                # descriptor for not equality, not used because gives bad results\n",
    "                # func2 = neq\n",
    "                # local1 = aux[:]\n",
    "                # local1.append((index_col_dict[i], j, func2))\n",
    "                # res.append(local1)\n",
    "\n",
    "    return res\n",
    "\n",
    "def put_item_in_queue(queue, quality, descriptor, size=0):\n",
    "    \"\"\"Adds an item to a priority queue based on its quality.\n",
    "\n",
    "    Args:\n",
    "        queue: The priority queue to which the item will be added.\n",
    "        quality: The quality measure of the item.\n",
    "        descriptor: The descriptor associated with the item.\n",
    "        size: The size of the subgroup represented by the descriptor.\n",
    "    \"\"\"\n",
    "    if queue.full():  # if the queue is full\n",
    "        min_quality, min_descriptor, min_size = queue.get()  # get the lowest quality item\n",
    "        if min_quality >= quality:  # if the new item is not better, put the old one back\n",
    "            queue.put((min_quality, min_descriptor, min_size))\n",
    "        else:  # otherwise, add the new item\n",
    "            queue.put((quality, descriptor, size))\n",
    "    else:\n",
    "        queue.put((quality, descriptor, size))  # add new item to the queue\n",
    "\n",
    "def categorize_columns_in_order(df, att_columns):\n",
    "    \"\"\"Categorizes columns of a DataFrame into numeric, binary, and nominal types.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame containing the data.\n",
    "        att_columns: The columns to categorize.\n",
    "\n",
    "    Returns:\n",
    "        A list of column types corresponding to the provided attribute columns.\n",
    "    \"\"\"\n",
    "    column_types = []  # List to store the categories in order\n",
    "\n",
    "    for col in att_columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):  # Check if the column is numeric\n",
    "            column_types.append('numeric')\n",
    "        elif df[col].nunique() == 2:  # Check for binary columns\n",
    "            column_types.append('binary')\n",
    "        else:  # Otherwise, treat it as nominal\n",
    "            column_types.append('nominal')\n",
    "\n",
    "    return column_types\n",
    "\n",
    "def make_rolling_windows(growth_target, window_size):\n",
    "    \"\"\"Creates rolling windows for the target data.\n",
    "\n",
    "    Args:\n",
    "        growth_target: The target data for which to create rolling windows.\n",
    "        window_size: The size of each window.\n",
    "\n",
    "    Returns:\n",
    "        A new array of rolling windows.\n",
    "    \"\"\"\n",
    "    return np.lib.stride_tricks.sliding_window_view(growth_target, window_shape=window_size)[::window_size]\n",
    "\n",
    "def quality_measure(targets_subgroup, targets_baseline,\n",
    "                    aggregate_func_window=np.mean, aggregate_func=np.max):\n",
    "    \"\"\"Calculates a quality measure for a subgroup compared to a baseline.\n",
    "\n",
    "    Args:\n",
    "        targets_subgroup: list with timeseries where the timeseries are divided in windows (list with lists with lists)\n",
    "        targets_baseline: list with baseline target values in windows (list with lists).\n",
    "        aggregate_func_window: Function to aggregate over windows (default: mean).\n",
    "        aggregate_func: Function to aggregate the final quality measure (default: max).\n",
    "\n",
    "    Returns:\n",
    "        A quality score representing the difference between the subgroup and baseline.\n",
    "    \"\"\"\n",
    "    # Aggregate points in each window for each timeseries in the subgroup\n",
    "    subgroup_aggregated_windows = aggregate_func_window(targets_subgroup, axis=2)\n",
    "\n",
    "    # Calculate mean values for the baseline and subgroup for each window\n",
    "    baseline_means = np.mean(targets_baseline, axis=1)\n",
    "    subgroup_means = np.mean(subgroup_aggregated_windows, axis=0)\n",
    "\n",
    "    # Calculate absolute differences between means for each window\n",
    "    abs_diff_mean = np.abs(subgroup_means - baseline_means)\n",
    "\n",
    "    # Calculate standard error of the subgroup for each window\n",
    "    subgroup_std = np.std(subgroup_aggregated_windows, axis=0)\n",
    "    \n",
    "    # Calculate z-scores\n",
    "    z_scores = abs_diff_mean / subgroup_std\n",
    "\n",
    "    # Calculate the final quality score\n",
    "    quality_score = aggregate_func(z_scores)\n",
    "\n",
    "    return quality_score\n",
    "\n",
    "\n",
    "def filter_df_on_descriptors(df, descriptors):\n",
    "    \"\"\"Filters a DataFrame based on specified descriptors.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame to filter.\n",
    "        descriptors: A list of descriptors, each containing an attribute name, value, and operator.\n",
    "\n",
    "    Returns:\n",
    "        A filtered DataFrame where all descriptors hold true.\n",
    "    \"\"\"\n",
    "    # Loop through each descriptor to apply filtering\n",
    "    for desc in descriptors:\n",
    "        # Apply the operator defined in the descriptor to filter the DataFrame\n",
    "        df = df[df[desc[0]].apply(lambda x: desc[2](x, desc[1]))]  # Filter based on the descriptor\n",
    "    return df  # Return the filtered DataFrame\n",
    "\n",
    "def get_all_descriptors(pq, index=1):\n",
    "    \"\"\"Retrieve all descriptors from a priority queue without altering its contents.\n",
    "\n",
    "    Args:\n",
    "        pq: A priority queue containing descriptor tuples.\n",
    "        index: The index of item to retrieve\n",
    "\n",
    "    Returns:\n",
    "        A list with info out of the results pq\n",
    "    \"\"\"\n",
    "    temp_items = []  # Temporary list to store all items from the queue\n",
    "    info = []  # List to store info of results pq (descriptors, quality, etc.)\n",
    "\n",
    "    # Retrieve all items from the queue\n",
    "    while not pq.empty():\n",
    "        item = pq.get()  # Get item from the queue\n",
    "        temp_items.append(item)  # Store the item temporarily\n",
    "        info.append(item[index])  # Extract and store the descriptor\n",
    "\n",
    "    # Put all items back into the queue to maintain its original state\n",
    "    for item in temp_items:\n",
    "        pq.put(item)\n",
    "\n",
    "    return info\n",
    "def beam_search_with_constraint_paper(data, targets_baseline, column_names, beam_width, beam_depth, nr_bins, nr_saved, subgroup_size, target, types, window_size, max_subgroup_size=100000):\n",
    "    \"\"\"Performs beam search with a constraint to avoid adding similar descriptors.\n",
    "\n",
    "    Args:\n",
    "        data: The dataset to analyze.\n",
    "        targets_baseline: The baseline target values for comparison.\n",
    "        column_names: The names of the columns in the dataset.\n",
    "        beam_width: The number of descriptors to keep at each depth level.\n",
    "        beam_depth: The maximum depth of the beam search.\n",
    "        nr_bins: The number of bins to create for numeric attributes.\n",
    "        nr_saved: The number of best results to save.\n",
    "        subgroup_size: The minimum size of a subgroup to consider.\n",
    "        target: The target variable for which to evaluate subgroups.\n",
    "        types: The types of each column in the dataset (e.g., numeric, binary, nominal).\n",
    "        window_size: The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        A list of the best descriptor sets found during the search, ensuring no similar descriptors.\n",
    "    \"\"\"\n",
    "    # Create dictionaries for indexing columns by name and vice versa\n",
    "    index_col_dict = {i: col for i, col in enumerate(column_names)}\n",
    "    col_index_dict = {col: i for i, col in enumerate(column_names)}\n",
    "    target_ind = column_names.index(target)  # Get index of the target column\n",
    "    att_indices = list(range(len(column_names)))  # Create a list of all indices\n",
    "    att_indices.remove(target_ind)  # Remove the target index from attribute indices\n",
    "\n",
    "    # Prepare data windows with rolling windows for the target variable\n",
    "    data_windows = []\n",
    "    for row in data:\n",
    "        new_row = row[:]  # Create a copy of the row\n",
    "        new_row[target_ind] = make_rolling_windows(row[target_ind], window_size)  # Apply rolling window\n",
    "        data_windows.append(new_row)  # Add the new row to data_windows\n",
    "\n",
    "    # Update the data and baseline targets to use rolling windows\n",
    "    data = data_windows\n",
    "    targets_baseline = make_rolling_windows(targets_baseline, window_size)\n",
    "\n",
    "    # Initialize a deque for the beam search and a priority queue for results\n",
    "    beam_queue = deque([()])  # Start with an empty seed\n",
    "    results = PriorityQueue(nr_saved)  # Queue to hold the best results\n",
    "    results.put((0, [(0, 0, 0)], 0))  # Add a dummy descriptor to initialize\n",
    "\n",
    "    # Iterate through each depth of the beam search\n",
    "    for depth in range(beam_depth):\n",
    "        beam = PriorityQueue(beam_width)  # Initialize a new beam for this depth\n",
    "\n",
    "        # While there are seeds in the beam queue\n",
    "        while bool(beam_queue):\n",
    "            seed = beam_queue.popleft()  # Get the next seed descriptor\n",
    "            descriptor_set = refin(seed, data, types, nr_bins, att_indices, index_col_dict, col_index_dict)  # Refine descriptors based on seed\n",
    "\n",
    "            # Evaluate each descriptor set generated\n",
    "            for descriptor in descriptor_set:\n",
    "                subgroup = extract_subgroup(descriptor, data, col_index_dict)  # Extract subgroup for the current descriptor\n",
    "                if len(subgroup) >= subgroup_size and len(subgroup) < max_subgroup_size:  # Ensure subgroup is large enough and descriptor is not similar\n",
    "                    targets_subgroup = [i[target_ind] for i in subgroup]  # Extract target values for the subgroup\n",
    "                    quality_result = quality_measure(targets_subgroup, targets_baseline)  # Calculate quality measure\n",
    "                    if not descriptors_similar_paper(quality_result, descriptor, results): # check if there are already subgroups with similar descriptors\n",
    "                        put_item_in_queue(results, quality_result, tuple(descriptor), len(subgroup))  # Add to results queue\n",
    "                        put_item_in_queue(beam, quality_result, tuple(descriptor))  # Add to the current beam\n",
    "\n",
    "        # After processing the beam, update the beam queue with new combinations\n",
    "        while not beam.empty():\n",
    "            new_combination = beam.get()  # Get the highest quality descriptor from the beam\n",
    "            new_combination = new_combination[1]  # Extract the descriptor from the tuple\n",
    "            beam_queue.append(new_combination)  # Add it to the next depth of the beam search\n",
    "\n",
    "    # Compile results into a list and reverse to have the best results first\n",
    "    results_list = []\n",
    "    while not results.empty():\n",
    "        item = results.get()  # Get items from the results queue\n",
    "        results_list.append(item)  # Add to the results list\n",
    "    results_list.reverse()  # Reverse the list to have best results first\n",
    "\n",
    "    return results_list  # Return the list of best descriptor sets\n",
    "\n",
    "def descriptors_similar_paper(quality, descriptor1, pq):\n",
    "\n",
    "    if len(descriptor1) == 1:\n",
    "        return False\n",
    "\n",
    "    tolerance = 0.1\n",
    "    desc1_dict = {metric: (value, func) for metric, value, func in descriptor1}\n",
    "    descriptor_list = get_all_descriptors(pq, 1)\n",
    "    quality_list = get_all_descriptors(pq, 0)\n",
    "\n",
    "    # Early exit if quality difference exceeds threshold\n",
    "    if min(abs(quality - q) for q in quality_list) > 1000:\n",
    "        return False\n",
    "\n",
    "    # Compare against each descriptor in the queue\n",
    "    for descriptor2 in descriptor_list:\n",
    "\n",
    "        desc2_dict = {metric: (value, func) for metric, value, func in descriptor2}\n",
    "\n",
    "        match_count = 0\n",
    "\n",
    "        for metric, (value1, func1) in desc1_dict.items():\n",
    "            if metric not in desc2_dict:\n",
    "                continue  # If a metric is missing, no need to continue\n",
    "\n",
    "            value2, func2 = desc2_dict[metric]\n",
    "\n",
    "            # Function mismatch, skip this descriptor\n",
    "            if func1 != func2:\n",
    "                continue\n",
    "\n",
    "            # Numeric comparison within tolerance\n",
    "            if isinstance(value1, (int, float)) and isinstance(value2, (int, float)):\n",
    "                if abs(value1 - value2) > abs(tolerance * value1):\n",
    "                    continue  # Values out of tolerance range\n",
    "\n",
    "            # String comparison for non-numeric values\n",
    "            elif isinstance(value1, str) and value1 != value2:\n",
    "                continue  # String values don't match\n",
    "\n",
    "            match_count += 1\n",
    "\n",
    "            # Early exit when all metrics except 1 match\n",
    "            if match_count >= len(descriptor1)-1:\n",
    "                return True\n",
    "\n",
    "    return False"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:46:17.125861Z",
     "start_time": "2024-10-10T15:45:45.993950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stock_df = make_growth_target_df('datasets/stock_data_for_emm.pkl')\n",
    "#stock_df.drop(['index'], inplace=True, axis=1)\n",
    "stock_df"
   ],
   "id": "e067637d5c231d62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             country                        industry currency  \\\n",
       "0             France             Aerospace & Defense      EUR   \n",
       "1            Germany            Software—Application      EUR   \n",
       "2              Italy                   Entertainment      EUR   \n",
       "3              Italy                  Packaged Foods      EUR   \n",
       "4     United Kingdom  Other Precious Metals & Mining      EUR   \n",
       "...              ...                             ...      ...   \n",
       "9774           Japan    Electrical Equipment & Parts      JPY   \n",
       "9775           Japan   Business Equipment & Supplies      JPY   \n",
       "9776           Japan  Electronic Gaming & Multimedia      JPY   \n",
       "9777           Japan           Electronic Components      JPY   \n",
       "9778           Japan              Auto Manufacturers      JPY   \n",
       "\n",
       "     exchangeTimezoneName exchange                  sector  \\\n",
       "0            Europe/Paris      PAR             Industrials   \n",
       "1           Europe/Berlin      GER              Technology   \n",
       "2             Europe/Rome      MIL  Communication Services   \n",
       "3             Europe/Rome      MIL      Consumer Defensive   \n",
       "4           Europe/Berlin      FRA         Basic Materials   \n",
       "...                   ...      ...                     ...   \n",
       "9774        Europe/London      LSE             Industrials   \n",
       "9775        Europe/London      LSE             Industrials   \n",
       "9776        Europe/London      LSE  Communication Services   \n",
       "9777        Europe/London      LSE              Technology   \n",
       "9778        Europe/London      LSE       Consumer Cyclical   \n",
       "\n",
       "      averageVolume10days  enterpriseToEbitda     marketCap  debtToEquity  \\\n",
       "0                   382.0              11.822  5.750674e+07        50.783   \n",
       "1                  8329.0              33.294  1.241838e+09        32.492   \n",
       "2                   330.0             -21.050  2.849466e+07       181.181   \n",
       "3                  3831.0               8.794  5.971590e+07        68.513   \n",
       "4                   108.0               1.402  2.123667e+08        81.212   \n",
       "...                   ...                 ...           ...           ...   \n",
       "9774               4893.0               6.287  2.079737e+10        10.654   \n",
       "9775               1940.0               5.531  5.086319e+09        35.268   \n",
       "9776               3530.0               7.976  6.297095e+09        18.311   \n",
       "9777                350.0               7.200  1.774490e+09         1.943   \n",
       "9778              72760.0              12.413  1.971894e+11       102.678   \n",
       "\n",
       "      fullTimeEmployees                                      growth_target  \n",
       "0                1102.0  [0.0, 1.17, 2.41, 0.41, 2.65, -1.39, -7.24, -4...  \n",
       "1                 650.0  [0.0, -1.84, 17.01, 3.7, -8.24, 8.01, -3.6, 4....  \n",
       "2                  34.0  [0.0, -7.96, -2.61, 0.89, 13.94, -4.85, -6.12,...  \n",
       "3                 232.0  [0.0, -3.39, 0.58, -10.17, 11.33, -2.91, 2.1, ...  \n",
       "4                3474.0  [0.0, 8.5, -15.79, 5.28, 2.24, -1.94, 7.5, -1....  \n",
       "...                 ...                                                ...  \n",
       "9774           145696.0  [0.0, 1.08, 10.44, -11.75, -11.15, 7.96, -9.17...  \n",
       "9775            78360.0  [0.0, 5.82, 1.71, 7.84, -10.55, 3.58, -7.94, 2...  \n",
       "9776             4894.0  [0.0, 6.5, 0.0, -10.85, -1.95, -3.62, -3.95, 9...  \n",
       "9777             1297.0  [0.0, 0.0, 0.0, 0.0, 18.86, 0.0, 0.0, 0.0, 10....  \n",
       "9778           376971.0  [0.0, 2.08, 5.28, -3.71, -7.07, 5.43, -4.35, 4...  \n",
       "\n",
       "[9779 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>industry</th>\n",
       "      <th>currency</th>\n",
       "      <th>exchangeTimezoneName</th>\n",
       "      <th>exchange</th>\n",
       "      <th>sector</th>\n",
       "      <th>averageVolume10days</th>\n",
       "      <th>enterpriseToEbitda</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>debtToEquity</th>\n",
       "      <th>fullTimeEmployees</th>\n",
       "      <th>growth_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Paris</td>\n",
       "      <td>PAR</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>382.0</td>\n",
       "      <td>11.822</td>\n",
       "      <td>5.750674e+07</td>\n",
       "      <td>50.783</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>[0.0, 1.17, 2.41, 0.41, 2.65, -1.39, -7.24, -4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Software—Application</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Berlin</td>\n",
       "      <td>GER</td>\n",
       "      <td>Technology</td>\n",
       "      <td>8329.0</td>\n",
       "      <td>33.294</td>\n",
       "      <td>1.241838e+09</td>\n",
       "      <td>32.492</td>\n",
       "      <td>650.0</td>\n",
       "      <td>[0.0, -1.84, 17.01, 3.7, -8.24, 8.01, -3.6, 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Rome</td>\n",
       "      <td>MIL</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>330.0</td>\n",
       "      <td>-21.050</td>\n",
       "      <td>2.849466e+07</td>\n",
       "      <td>181.181</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[0.0, -7.96, -2.61, 0.89, 13.94, -4.85, -6.12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Packaged Foods</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Rome</td>\n",
       "      <td>MIL</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>3831.0</td>\n",
       "      <td>8.794</td>\n",
       "      <td>5.971590e+07</td>\n",
       "      <td>68.513</td>\n",
       "      <td>232.0</td>\n",
       "      <td>[0.0, -3.39, 0.58, -10.17, 11.33, -2.91, 2.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Other Precious Metals &amp; Mining</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Europe/Berlin</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.402</td>\n",
       "      <td>2.123667e+08</td>\n",
       "      <td>81.212</td>\n",
       "      <td>3474.0</td>\n",
       "      <td>[0.0, 8.5, -15.79, 5.28, 2.24, -1.94, 7.5, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9774</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Electrical Equipment &amp; Parts</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>4893.0</td>\n",
       "      <td>6.287</td>\n",
       "      <td>2.079737e+10</td>\n",
       "      <td>10.654</td>\n",
       "      <td>145696.0</td>\n",
       "      <td>[0.0, 1.08, 10.44, -11.75, -11.15, 7.96, -9.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9775</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Business Equipment &amp; Supplies</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>5.531</td>\n",
       "      <td>5.086319e+09</td>\n",
       "      <td>35.268</td>\n",
       "      <td>78360.0</td>\n",
       "      <td>[0.0, 5.82, 1.71, 7.84, -10.55, 3.58, -7.94, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Electronic Gaming &amp; Multimedia</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>7.976</td>\n",
       "      <td>6.297095e+09</td>\n",
       "      <td>18.311</td>\n",
       "      <td>4894.0</td>\n",
       "      <td>[0.0, 6.5, 0.0, -10.85, -1.95, -3.62, -3.95, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9777</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Electronic Components</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Technology</td>\n",
       "      <td>350.0</td>\n",
       "      <td>7.200</td>\n",
       "      <td>1.774490e+09</td>\n",
       "      <td>1.943</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 18.86, 0.0, 0.0, 0.0, 10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Auto Manufacturers</td>\n",
       "      <td>JPY</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>LSE</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>72760.0</td>\n",
       "      <td>12.413</td>\n",
       "      <td>1.971894e+11</td>\n",
       "      <td>102.678</td>\n",
       "      <td>376971.0</td>\n",
       "      <td>[0.0, 2.08, 5.28, -3.71, -7.07, 5.43, -4.35, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9779 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:46:37.790881Z",
     "start_time": "2024-10-10T15:46:17.257770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = stock_df.values.tolist()\n",
    "column_names = list(stock_df.columns)\n",
    "beam_width = 10\n",
    "beam_depth = 3\n",
    "nr_bins = 8\n",
    "nr_saved = 10\n",
    "subgroup_size = len(data) * 0.05\n",
    "target = 'growth_target'\n",
    "window_size = 5\n",
    "target_ind = column_names.index(target)\n",
    "all_time_series = [i[target_ind] for i in data]\n",
    "all_time_series = np.array(all_time_series)\n",
    "targets_baseline = np.mean(all_time_series, axis=0)\n",
    "att_indices = list(range(0, len(column_names)))\n",
    "att_indices.remove(target_ind)\n",
    "att_columns = [column_names[i] for i in att_indices]\n",
    "types = categorize_columns_in_order(stock_df, att_columns)\n",
    "results = beam_search_with_constraint_paper(data, targets_baseline, column_names, beam_width, beam_depth, nr_bins,\n",
    "                                                  nr_saved, subgroup_size, target, types, window_size)\n"
   ],
   "id": "407bd4c92dabb933",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:46:37.867982Z",
     "start_time": "2024-10-10T15:46:37.854021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for r in results:\n",
    "    print(r[:3])\n",
    "    print('\\n')"
   ],
   "id": "c248b4f526e07c30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.509657278408514, (('country', 'Japan', <function eq at 0x00000141EB849630>), ('enterpriseToEbitda', -1.044, <function gt at 0x00000141BA7917E0>), ('enterpriseToEbitda', 3.978, <function leeq at 0x00000141EB8495A0>)), 494)\n",
      "\n",
      "\n",
      "(6.431800142548485, (('country', 'Japan', <function eq at 0x00000141EB849630>), ('enterpriseToEbitda', -1.044, <function gt at 0x00000141BA7917E0>), ('enterpriseToEbitda', 7.976, <function leeq at 0x00000141EB8495A0>)), 575)\n",
      "\n",
      "\n",
      "(6.205676446380705, (('country', 'Japan', <function eq at 0x00000141EB849630>), ('enterpriseToEbitda', -1.044, <function gt at 0x00000141BA7917E0>)), 656)\n",
      "\n",
      "\n",
      "(6.035047292325761, (('country', 'Japan', <function eq at 0x00000141EB849630>), ('enterpriseToEbitda', -1.044, <function gt at 0x00000141BA7917E0>), ('enterpriseToEbitda', -0.356, <function gt at 0x00000141BA7917E0>)), 573)\n",
      "\n",
      "\n",
      "(5.9640679219777635, (('country', 'Japan', <function eq at 0x00000141EB849630>), ('enterpriseToEbitda', -1.044, <function gt at 0x00000141BA7917E0>), ('enterpriseToEbitda', 0.268, <function gt at 0x00000141BA7917E0>)), 491)\n",
      "\n",
      "\n",
      "(5.773707403771755, (('marketCap', 28408813568.0, <function gt at 0x00000141BA7917E0>), ('marketCap', 195621847040.0, <function leeq at 0x00000141EB8495A0>), ('averageVolume10days', 1944.0, <function gt at 0x00000141BA7917E0>)), 534)\n",
      "\n",
      "\n",
      "(5.670155231271532, (('marketCap', 28408813568.0, <function gt at 0x00000141BA7917E0>), ('marketCap', 117536301056.0, <function leeq at 0x00000141EB8495A0>), ('averageVolume10days', 329.0, <function gt at 0x00000141BA7917E0>)), 573)\n",
      "\n",
      "\n",
      "(5.663785340668793, (('marketCap', 28408813568.0, <function gt at 0x00000141BA7917E0>), ('marketCap', 117536301056.0, <function leeq at 0x00000141EB8495A0>), ('fullTimeEmployees', 18201.0, <function gt at 0x00000141BA7917E0>)), 684)\n",
      "\n",
      "\n",
      "(5.642104748988323, (('marketCap', 28408813568.0, <function gt at 0x00000141BA7917E0>), ('marketCap', 83129532416.0, <function leeq at 0x00000141EB8495A0>), ('fullTimeEmployees', 16815.0, <function gt at 0x00000141BA7917E0>)), 571)\n",
      "\n",
      "\n",
      "(5.639128921789861, (('marketCap', 28408813568.0, <function gt at 0x00000141BA7917E0>), ('marketCap', 117536301056.0, <function leeq at 0x00000141EB8495A0>), ('fullTimeEmployees', 31000.0, <function gt at 0x00000141BA7917E0>)), 572)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
