{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "from quality_measure import quality_measure\n",
    "from load_data import make_growth_target_df\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stock_df from the target file\n",
    "stock_df = make_growth_target_df('stock_data_for_emm.pkl')\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "stock_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Extract the growth target column\n",
    "growth_data = stock_df.loc[:, \"growth_target\"]\n",
    "\n",
    "# Get the indices of rows with NaN or Inf values\n",
    "nan_indices = growth_data[growth_data.apply(lambda x: any(pd.isna(i) for i in x))].index.tolist()\n",
    "inf_indices = growth_data[growth_data.apply(lambda x: any(i in [np.inf, -np.inf] for i in x))].index.tolist()\n",
    "\n",
    "# Get the union of the two indices\n",
    "union = list(set(nan_indices).union(set(inf_indices)))\n",
    "\n",
    "\n",
    "# Drop the rows with NaN or Inf values and reset the index\n",
    "stock_df = stock_df.drop(union).reset_index(drop=True)\n",
    "\n",
    "# Convert stock_df to a list of lists (values)\n",
    "stock_data = stock_df.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_series = [i[12] for i in stock_data]\n",
    "all_time_series = np.array(all_time_series)\n",
    "targets_baseline = np.mean(all_time_series, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(stock_df.columns)\n",
    "targets = ['target', 'growth_target']\n",
    "target_ind = [column_names.index(a) for a in targets]\n",
    "att_indices = list(range(0, len(column_names)))\n",
    "[att_indices.remove(i) for i in target_ind]\n",
    "att_columns = [column_names[i] for i in att_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gteq(a, b):\n",
    "    return a >= b\n",
    "\n",
    "def leeq(a, b):\n",
    "    return a <= b\n",
    "\n",
    "def eq(a, b):\n",
    "    return a == b\n",
    "\n",
    "def neq(a, b):\n",
    "    return not eq(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subgroup(descriptors, data):\n",
    "    result = []\n",
    "    for row in data:\n",
    "        check = True\n",
    "        for attribute in descriptors:\n",
    "            att_index, descr_value, operator = attribute # unpack 3 values from attribute\n",
    "            value = operator(row[att_index], descr_value)\n",
    "\n",
    "            if not value:\n",
    "                check = False\n",
    "                break\n",
    "        \n",
    "        if check:\n",
    "            result.append(row)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def refin(seed, data, types, nr_bins, descr_indices):\n",
    "\n",
    "    res = []\n",
    "    used_descr = [i[0] for i in seed]\n",
    "\n",
    "    not_used_descr = descr_indices[:]\n",
    "    [not_used_descr.remove(i) for i in used_descr]\n",
    "\n",
    "    # refinement of descriptors\n",
    "\n",
    "    for i in descr_indices: # functies voor voorwaarden gewoon erin doen\n",
    "        aux = list(seed)[:]\n",
    "\n",
    "        if types[i] == 'numeric':\n",
    "            s = extract_subgroup(seed, data)\n",
    "            all_values = [float(entry[i]) for entry in s]\n",
    "            all_values = sorted(all_values)\n",
    "            n = len(all_values)\n",
    "            split_points = [all_values[math.floor(j * (n/nr_bins))] for j in range(0, nr_bins-1)]\n",
    "            for s in split_points:\n",
    "                func1 = leeq\n",
    "                func2 = gteq\n",
    "                local0 = aux[:]\n",
    "                local0.append((i, s, func1))\n",
    "                local1 = aux[:]\n",
    "                local1.append((i, s, func2))\n",
    "                res.append(local0)\n",
    "                res.append(local1)\n",
    "\n",
    "        elif types[i] == 'binary':\n",
    "            func = eq\n",
    "            local0 = aux[:]\n",
    "            local0.append((i, 0, func))\n",
    "            local1 = aux[:]\n",
    "            local1.append((i, 1, func))\n",
    "            res.append(local0)\n",
    "            res.append(local1)\n",
    "\n",
    "        else:\n",
    "            all_values = [entry[i] for entry in data]\n",
    "            for j in set(all_values):\n",
    "                func1 = eq\n",
    "                func2 = neq\n",
    "                local0 = aux[:]\n",
    "                local0.append((i, j, func1))\n",
    "                res.append(local0)\n",
    "\n",
    "    return res\n",
    "\n",
    "            \n",
    "\n",
    "def constraints_satisfied(descriptors, constraints): # and subgroup len > 0\n",
    "    return True\n",
    "\n",
    "def insert_to_pq(descriptors:tuple, quality):\n",
    "    pass\n",
    "\n",
    "def get_highest_pq():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(data, targets_baseline, column_names, quality, refin, beam_width, beam_depth, nr_bins, nr_saved, constraints, targets, types):\n",
    "\n",
    "    target_ind = [column_names.index(a) for a in targets]\n",
    "    att_indices = list(range(0, len(column_names)))\n",
    "    [att_indices.remove(i) for i in target_ind]\n",
    "    target_ind.remove(11) # ONLY INCLUDE TARGET GROWTH!\n",
    "\n",
    "    beam_queue = deque([()]) # initialize with emtpy tuple (the empty set)\n",
    "    results = PriorityQueue(nr_saved) # queue with max amount of descriptors saved\n",
    "\n",
    "    for depth in range(beam_depth):\n",
    "        beam = PriorityQueue(beam_width) # amount of combinations we keep investigating\n",
    "    \n",
    "        while bool(beam_queue): # while there are items in the queue\n",
    "            seed = beam_queue.popleft()\n",
    "            descriptor_set = refin(seed, data, types, nr_bins, att_indices)\n",
    "\n",
    "            for descriptor in descriptor_set:\n",
    "                subgroup = extract_subgroup(descriptor, data)\n",
    "                \n",
    "                if constraints_satisfied(descriptor, constraints):\n",
    "                    targets_subgroup = [i[target_ind[0]] for i in subgroup]\n",
    "                    quality_result = quality(targets_subgroup, targets_baseline)\n",
    "                    print(quality_result)\n",
    "                    results.put(-quality_result, tuple(descriptor)) # nog checken of dit klopt\n",
    "                    beam.put(-quality_result, tuple(descriptor))\n",
    "                    print(beam)\n",
    "                    print(results)\n",
    "\n",
    "\n",
    "        while not beam.empty(): # is not empty\n",
    "            new_combination = beam.get() # dit moet het item gaan geven met de beste quality measure\n",
    "            beam_queue.append(new_combination)\n",
    "\n",
    "        break\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stock_data\n",
    "quality = quality_measure\n",
    "beam_width = 3\n",
    "beam_depth = 1\n",
    "nr_bins = 3\n",
    "nr_saved = 10\n",
    "constraints = None\n",
    "targets = ['target', 'growth_target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_columns_in_order(df, att_columns):\n",
    "    # Define empty list to store the categories in order\n",
    "    column_types = []\n",
    "    \n",
    "    # Loop through attribute columns in the DataFrame\n",
    "    for col in att_columns:\n",
    "        # Check if the column is numeric\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            column_types.append('numeric')\n",
    "        # Check if the column has exactly 2 unique values (binary)\n",
    "        elif df[col].nunique() == 2:\n",
    "            column_types.append('binary')\n",
    "        # Otherwise, treat it as nominal\n",
    "        else:\n",
    "            column_types.append('nominal')\n",
    "    \n",
    "    return column_types\n",
    "\n",
    "# Apply the function to the stock DataFrame\n",
    "types = categorize_columns_in_order(stock_df, att_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "739.312334442922\n",
      "131.55992375069735\n",
      "382.01150464991457\n",
      "524.7172056150646\n"
     ]
    }
   ],
   "source": [
    "beam_search(data, targets_baseline, column_names, quality, refin, beam_width, beam_depth, nr_bins, nr_saved, constraints, targets, types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
